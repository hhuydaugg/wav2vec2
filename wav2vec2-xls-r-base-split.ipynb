{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13549003,"sourceType":"datasetVersion","datasetId":8605016},{"sourceId":624743,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":470135,"modelId":486029},{"sourceId":624823,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":470204,"modelId":486098}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4","name":"wav2vec2_XLS-R base"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\nimport torchaudio\nfrom torch.optim import AdamW\nfrom transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve\nfrom sklearn.utils import resample\nfrom tqdm.notebook import tqdm\nimport gc # Garbage collector","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:53:55.051833Z","iopub.execute_input":"2025-11-08T15:53:55.052131Z","iopub.status.idle":"2025-11-08T15:54:26.174227Z","shell.execute_reply.started":"2025-11-08T15:53:55.052107Z","shell.execute_reply":"2025-11-08T15:54:26.173510Z"},"id":"3M1cTW_GEMFf","outputId":"ba258683-c89c-4b20-f1cf-80a22e7f588a"},"outputs":[{"name":"stderr","text":"2025-11-08 15:54:08.296961: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762617248.484279      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762617248.537214      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# --- Configuration ---\nDATASET_PATH = \"/kaggle/input/asvspoof2019-la/LA\"\nPROTOCOLS_PATH = os.path.join(DATASET_PATH, \"ASVspoof2019_LA_cm_protocols\")\nAUDIO_DIRS = {\n    \"train\": os.path.join(DATASET_PATH, \"ASVspoof2019_LA_train/flac\"),\n    \"dev\": os.path.join(DATASET_PATH, \"ASVspoof2019_LA_dev/flac\"),\n    \"eval\": os.path.join(DATASET_PATH, \"ASVspoof2019_LA_eval/flac\"),\n}\nPROTOCOL_FILES = {\n    \"train\": os.path.join(PROTOCOLS_PATH, \"ASVspoof2019.LA.cm.train.trn.txt\"),\n    \"dev\": os.path.join(PROTOCOLS_PATH, \"ASVspoof2019.LA.cm.dev.trl.txt\"),\n    \"eval\": os.path.join(PROTOCOLS_PATH, \"ASVspoof2019.LA.cm.eval.trl.txt\"),\n}\nMODEL_SAVE_PATH = \"/kaggle/working/\" # Or \"./\" if running locally\nBEST_MODEL_NAME = \"wav2vec2_deepfake_best.pt\"\nFINAL_MODEL_NAME = \"wav2vec2_deepfake_final.pt\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:54:38.426434Z","iopub.execute_input":"2025-11-08T15:54:38.427377Z","iopub.status.idle":"2025-11-08T15:54:38.431885Z","shell.execute_reply.started":"2025-11-08T15:54:38.427351Z","shell.execute_reply":"2025-11-08T15:54:38.431124Z"},"id":"SEgoY6jXEMFg"},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Model & Training Hyperparameters\nMODEL_IDENTIFIER = \"facebook/wav2vec2-xls-r-300m\"\nTARGET_SAMPLE_RATE = 16000 # XLS-R also expects 16kHz\nMAX_AUDIO_SECONDS = 5 # Max duration to process\nMAX_LENGTH = TARGET_SAMPLE_RATE * MAX_AUDIO_SECONDS\n\nBATCH_SIZE = 16 # Adjust based on GPU memory (XLS-R might require slightly more memory)\nEPOCHS = 15 # Initial training epochs\nLEARNING_RATE = 5e-4\nFINETUNE_EPOCHS = 3\nFINETUNE_LR = 2e-5 # Fine-tuning LR might need adjustment for XLS-R\nEARLY_STOPPING_PATIENCE = 5\nNUM_WORKERS = 4 # Number of parallel data loading workers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:54:43.568669Z","iopub.execute_input":"2025-11-08T15:54:43.568945Z","iopub.status.idle":"2025-11-08T15:54:43.573346Z","shell.execute_reply.started":"2025-11-08T15:54:43.568925Z","shell.execute_reply":"2025-11-08T15:54:43.572625Z"},"id":"aSwysxGJEMFh"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Data Balancing\nSAMPLES_PER_CLASS_TRAIN = 5000\nSAMPLES_PER_CLASS_DEV_EVAL = 1250\n\n# Determine device\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {DEVICE}\")\nprint(f\"Using model: {MODEL_IDENTIFIER}\")\n\n# Create output directory if it doesn't exist\nos.makedirs(MODEL_SAVE_PATH, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:54:46.916569Z","iopub.execute_input":"2025-11-08T15:54:46.917192Z","iopub.status.idle":"2025-11-08T15:54:46.922087Z","shell.execute_reply.started":"2025-11-08T15:54:46.917168Z","shell.execute_reply":"2025-11-08T15:54:46.921331Z"},"id":"gEqJkTl8EMFh","outputId":"827ceaf4-fdb4-4205-9f14-3a1cf4064837"},"outputs":[{"name":"stdout","text":"Using device: cuda\nUsing model: facebook/wav2vec2-xls-r-300m\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- 1. Load Protocol Data & Stratified Splitting and Sampling ---\ndef load_protocol(protocol_path, audio_dir):\n    \"\"\"Loads protocol and adds full file paths, including Spoof_Type.\"\"\"\n    try:\n        # Check if protocol file exists\n        if not os.path.exists(protocol_path):\n             print(f\"Error: Protocol file not found at {protocol_path}\")\n             return pd.DataFrame(columns=[\"Speaker_ID\", \"File_ID\", \"-\", \"Spoof_Type\", \"Label\"])\n\n        df = pd.read_csv(protocol_path, sep=\" \", header=None,\n                         names=[\"Speaker_ID\", \"File_ID\", \"-\", \"Spoof_Type\", \"Label\"])\n        # Keep Spoof_Type for stratification\n        df = df[[\"File_ID\", \"Spoof_Type\", \"Label\"]]\n        df[\"Label\"] = df[\"Label\"].map({\"bonafide\": 1, \"spoof\": 0}) # 1 for real, 0 for fake\n\n        df['filepath'] = df['File_ID'].apply(lambda x: os.path.join(audio_dir, x + '.flac'))\n\n        # Filter out files that don't exist\n        original_count = len(df)\n        df = df[df['filepath'].apply(os.path.exists)].reset_index(drop=True)\n        filtered_count = len(df)\n        if original_count != filtered_count:\n            print(f\"Warning: {original_count - filtered_count} files not found for {os.path.basename(protocol_path)}.\")\n\n        print(f\"Loaded {os.path.basename(protocol_path)}: {len(df)} samples total \"\n              f\"({len(df[df['Label']==1])} real, {len(df[df['Label']==0])} fake)\")\n        return df\n\n    except FileNotFoundError: # Should be caught by os.path.exists, but keep as fallback\n        print(f\"Error: Protocol file not found at {protocol_path}\")\n        return pd.DataFrame(columns=[\"File_ID\", \"Spoof_Type\", \"Label\", \"filepath\"])\n    except Exception as e:\n        print(f\"Error loading protocol {protocol_path}: {e}\")\n        return pd.DataFrame(columns=[\"File_ID\", \"Spoof_Type\", \"Label\", \"filepath\"])\n\n\ndef stratified_sample(df, target_samples, stratify_col, random_state=42):\n    \"\"\"\n    Performs stratified sampling on a dataframe.\n    Samples proportionally from each group defined by stratify_col,\n    taking all samples if a group is smaller than its target proportion.\n    \"\"\"\n    if df.empty or target_samples <= 0:\n        print(\"Warning: Cannot sample from empty dataframe or with non-positive target samples.\")\n        return pd.DataFrame(columns=df.columns)\n\n    # Handle potential missing 'Spoof_Type' values for stratification\n    df['_Stratify_Helper'] = df[stratify_col].fillna('Bonafide')\n\n    group_counts = df['_Stratify_Helper'].value_counts()\n    total_samples_in_df = len(df)\n\n    sampled_df = pd.DataFrame(columns=df.columns)\n\n    for group_name, count in group_counts.items():\n        # Calculate the target number of samples for this group\n        # Ensure we don't request more samples than are available in the group\n        target_group_samples = min(count, int(np.ceil((count / total_samples_in_df) * target_samples)))\n\n        if target_group_samples > 0:\n            # Sample from the current group\n            group_df = df[df['_Stratify_Helper'] == group_name]\n            sampled_group = group_df.sample(n=target_group_samples, random_state=random_state, replace=False)\n            sampled_df = pd.concat([sampled_df, sampled_group], ignore_index=True)\n        else:\n             print(f\"Warning: Skipping sampling for group '{group_name}' as target is 0.\")\n\n\n    # Clean up helper column\n    sampled_df = sampled_df.drop(columns=['_Stratify_Helper'])\n    df = df.drop(columns=['_Stratify_Helper']) # Drop from original df too\n\n    print(f\"Sampled {len(sampled_df)} samples (target was {target_samples}).\")\n    return sampled_df\n\nprint(\"Loading full protocols for splitting and sampling...\")\n# Check if base path exists (useful feedback in Kaggle)\nif not os.path.exists(DATASET_PATH):\n    print(f\"Warning: Base data path not found at {DATASET_PATH}. Check dataset mounting.\")\nif not os.path.exists(PROTOCOLS_PATH):\n     print(f\"Warning: Protocols path not found at {PROTOCOLS_PATH}.\")\n\n\n# Load full protocols for each set initially\ndf_train_full = load_protocol(PROTOCOL_FILES[\"train\"], AUDIO_DIRS[\"train\"])\ndf_dev_full = load_protocol(PROTOCOL_FILES[\"dev\"], AUDIO_DIRS[\"dev\"])\ndf_eval_full = load_protocol(PROTOCOL_FILES[\"eval\"], AUDIO_DIRS[\"eval\"])\n\n\n# --- Perform Stratified Sampling ---\nTARGET_TRAIN_SAMPLES = 10000\nTARGET_DEV_SAMPLES = 1250\nTARGET_EVAL_SAMPLES = 1250\n\n\nprint(f\"\\nSampling {TARGET_TRAIN_SAMPLES} training samples (stratified)...\")\ndf_train = stratified_sample(df_train_full, TARGET_TRAIN_SAMPLES, 'Spoof_Type')\n\nprint(f\"\\nSampling {TARGET_DEV_SAMPLES} development samples (stratified)...\")\ndf_dev = stratified_sample(df_dev_full, TARGET_DEV_SAMPLES, 'Spoof_Type')\n\nprint(f\"\\nSampling {TARGET_EVAL_SAMPLES} evaluation samples (stratified)...\")\ndf_eval = stratified_sample(df_eval_full, TARGET_EVAL_SAMPLES, 'Spoof_Type')\n\n\n# --- Check if dataframes are empty ---\nif df_train.empty or df_dev.empty or df_eval.empty:\n    raise ValueError(\"One or more dataframes (train, dev, eval) are empty after sampling. Check data paths and sampling logic.\")\n\nprint(\"\\nTrain dataset distribution (after sampling):\")\nprint(df_train['Label'].value_counts())\nprint(\"\\nDev dataset distribution (after sampling):\")\nprint(df_dev['Label'].value_counts())\nprint(\"\\nEval dataset distribution (after sampling):\")\nprint(df_eval['Label'].value_counts())\n\n# Verify Spoof_Type distribution in sampled splits\nprint(\"\\nTrain dataset Spoof_Type distribution (after sampling):\")\nprint(df_train['Spoof_Type'].value_counts())\nprint(\"\\nDev dataset Spoof_Type distribution (after sampling):\")\nprint(df_dev['Spoof_Type'].value_counts())\nprint(\"\\nEval dataset Spoof_Type distribution (after sampling):\")\nprint(df_eval['Spoof_Type'].value_counts())\n\n\n# Clean up original full dataframes\ndel df_train_full, df_dev_full, df_eval_full\ngc.collect()\nif DEVICE.type == 'cuda': torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:54:50.224841Z","iopub.execute_input":"2025-11-08T15:54:50.225458Z","iopub.status.idle":"2025-11-08T16:02:45.912661Z","shell.execute_reply.started":"2025-11-08T15:54:50.225432Z","shell.execute_reply":"2025-11-08T16:02:45.911941Z"},"id":"DREPIZBcEMFh","outputId":"a3d0ad2e-b279-4bdf-c1df-f8a0a06676ea"},"outputs":[{"name":"stdout","text":"Loading full protocols for splitting and sampling...\nLoaded ASVspoof2019.LA.cm.train.trn.txt: 25380 samples total (2580 real, 22800 fake)\nLoaded ASVspoof2019.LA.cm.dev.trl.txt: 24844 samples total (2548 real, 22296 fake)\nLoaded ASVspoof2019.LA.cm.eval.trl.txt: 71237 samples total (7355 real, 63882 fake)\n\nSampling 10000 training samples (stratified)...\nSampled 10005 samples (target was 10000).\n\nSampling 1250 development samples (stratified)...\nSampled 1251 samples (target was 1250).\n\nSampling 1250 evaluation samples (stratified)...\nSampled 1261 samples (target was 1250).\n\nTrain dataset distribution (after sampling):\nLabel\n0    8988\n1    1017\nName: count, dtype: int64\n\nDev dataset distribution (after sampling):\nLabel\n0    1122\n1     129\nName: count, dtype: int64\n\nEval dataset distribution (after sampling):\nLabel\n0    1131\n1     130\nName: count, dtype: int64\n\nTrain dataset Spoof_Type distribution (after sampling):\nSpoof_Type\nA01    1498\nA02    1498\nA03    1498\nA05    1498\nA04    1498\nA06    1498\n-      1017\nName: count, dtype: int64\n\nDev dataset Spoof_Type distribution (after sampling):\nSpoof_Type\nA01    187\nA02    187\nA03    187\nA05    187\nA04    187\nA06    187\n-      129\nName: count, dtype: int64\n\nEval dataset Spoof_Type distribution (after sampling):\nSpoof_Type\n-      130\nA11     87\nA14     87\nA16     87\nA09     87\nA13     87\nA12     87\nA18     87\nA15     87\nA08     87\nA17     87\nA10     87\nA07     87\nA19     87\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# --- Calculate Class Weights for Training Set ---\nprint(\"\\nCalculating class weights for training set...\")\nclass_counts = df_train['Label'].value_counts().sort_index()\nif len(class_counts) == 2: # Ensure both classes are present\n    total_samples = len(df_train)\n    weight_for_0 = total_samples / (2.0 * class_counts[0])\n    weight_for_1 = total_samples / (2.0 * class_counts[1])\n    class_weights = torch.tensor([weight_for_0, weight_for_1], dtype=torch.float)\n    print(f\"Class weights: {class_weights}\")\n    class_weights = class_weights.to(DEVICE) # Move weights to the correct device\nelse:\n    print(\"Warning: Training data does not contain both classes. Cannot calculate weights.\")\n    class_weights = None # Handle this case in criterion initialization\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:17:46.182369Z","iopub.execute_input":"2025-11-08T16:17:46.183011Z","iopub.status.idle":"2025-11-08T16:17:46.348246Z","shell.execute_reply.started":"2025-11-08T16:17:46.182985Z","shell.execute_reply":"2025-11-08T16:17:46.347418Z"},"id":"3MurNvO23Hfu","outputId":"1fe3d936-5838-4481-9383-b5882c4e1be3"},"outputs":[{"name":"stdout","text":"\nCalculating class weights for training set...\nClass weights: tensor([0.5566, 4.9189])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# --- 2. PyTorch Dataset ---\nclass AudioDataset(Dataset):\n    \"\"\"PyTorch Dataset for loading and processing audio files.\"\"\"\n    def __init__(self, dataframe, feature_extractor, target_sr=TARGET_SAMPLE_RATE, max_length=MAX_LENGTH):\n        self.df = dataframe\n        self.feature_extractor = feature_extractor # Use feature_extractor\n        self.target_sr = target_sr\n        self.max_length = max_length\n        # Pre-create resampler if target_sr is fixed\n        self.resampler_cache = {}\n\n    def __len__(self):\n        return len(self.df)\n\n    def _get_resampler(self, orig_freq, new_freq):\n        \"\"\"Cache resamplers to avoid recreating them repeatedly.\"\"\"\n        if (orig_freq, new_freq) not in self.resampler_cache:\n            self.resampler_cache[(orig_freq, new_freq)] = torchaudio.transforms.Resample(orig_freq=orig_freq, new_freq=new_freq)\n        return self.resampler_cache[(orig_freq, new_freq)]\n\n    def __getitem__(self, idx):\n        if idx >= len(self.df):\n             raise IndexError(\"Index out of bounds\")\n\n        row = self.df.iloc[idx]\n        audio_path = row['filepath']\n        label = row['Label']\n\n        try:\n            waveform, sample_rate = torchaudio.load(audio_path)\n\n            if waveform.shape[0] > 1:\n                waveform = torch.mean(waveform, dim=0, keepdim=True)\n\n            if sample_rate != self.target_sr:\n                # Use functional resampling which might be slightly faster without caching object\n                waveform = torchaudio.functional.resample(waveform, orig_freq=sample_rate, new_freq=self.target_sr)\n                # Or use cached resampler:\n                # resampler = self._get_resampler(sample_rate, self.target_sr)\n                # waveform = resampler(waveform)\n\n\n            # Truncate or pad waveform\n            if waveform.shape[1] > self.max_length:\n                waveform = waveform[:, :self.max_length]\n            # Padding is handled by the feature extractor's __call__ method\n\n            # Process using the feature extractor\n            # Squeeze to remove channel dimension for feature extractor if it's mono\n            inputs = self.feature_extractor(\n                waveform.squeeze(0),\n                sampling_rate=self.target_sr,\n                return_tensors=\"pt\",\n                padding=\"max_length\", # Pad to a consistent length (model's max or specified max)\n                max_length=self.max_length, # Use the same max length for padding\n                truncation=True # Ensure truncation if somehow still longer after manual truncate\n            )\n\n            # The feature extractor output is nested, get the input_values tensor\n            input_values = inputs.input_values.squeeze(0) # Remove batch dim added by feature_extractor\n\n            return {\"input_values\": input_values, \"labels\": torch.tensor(label, dtype=torch.long)}\n\n        except Exception as e:\n            print(f\"Error processing file {audio_path} at index {idx}: {e}\")\n            # Return None or raise error, or return a dummy sample\n            # Returning dummy sample to avoid crashing the loader entirely\n            # Adjust dummy shape based on expected feature extractor output if needed\n            dummy_input = torch.zeros(self.max_length) # Adjust size if needed\n            # Need to process the dummy input to get the correct shape after feature extraction\n            dummy_processed = self.feature_extractor(dummy_input, sampling_rate=self.target_sr, return_tensors=\"pt\", padding=\"max_length\", max_length=self.max_length, truncation=True)\n            return {\"input_values\": dummy_processed.input_values.squeeze(0), \"labels\": torch.tensor(-1, dtype=torch.long)} # Use -1 label for errors\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:17:54.293879Z","iopub.execute_input":"2025-11-08T16:17:54.294567Z","iopub.status.idle":"2025-11-08T16:17:54.308651Z","shell.execute_reply.started":"2025-11-08T16:17:54.294536Z","shell.execute_reply":"2025-11-08T16:17:54.307786Z"},"id":"QJ4wRSD6EMFi"},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# --- 3. Initialize Processor and Create Datasets/DataLoaders ---\nprint(f\"Initializing processor for {MODEL_IDENTIFIER}...\")\n# Load only the feature extractor\nfeature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\n    MODEL_IDENTIFIER,\n    sampling_rate=TARGET_SAMPLE_RATE # Ensure target sample rate is set\n)\nprint(\"Creating datasets...\")\ntrain_dataset = AudioDataset(df_train, feature_extractor, TARGET_SAMPLE_RATE,MAX_LENGTH)\ndev_dataset = AudioDataset(df_dev, feature_extractor, TARGET_SAMPLE_RATE,MAX_LENGTH)\neval_dataset = AudioDataset(df_eval, feature_extractor, TARGET_SAMPLE_RATE,MAX_LENGTH)\n\n# Custom collate function to handle potential errors from __getitem__\ndef collate_fn(batch):\n    batch = [item for item in batch if item is not None and item[\"labels\"] != -1]\n    if not batch:\n        return None\n    try:\n        input_values = torch.stack([item[\"input_values\"] for item in batch])\n        labels = torch.stack([item[\"labels\"] for item in batch])\n        return {\n            \"input_values\": input_values,\n            \"labels\": labels\n        }\n    except Exception as e:\n        print(f\"Error during collation: {e}\")\n        return None\n\n\nprint(\"Creating data loaders...\")\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS,\n                          collate_fn=collate_fn, pin_memory=True, persistent_workers=(NUM_WORKERS > 0))\ndev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n                        collate_fn=collate_fn, pin_memory=True, persistent_workers=(NUM_WORKERS > 0))\neval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n                         collate_fn=collate_fn, pin_memory=True, persistent_workers=(NUM_WORKERS > 0))\n\nprint(f\"Train loader batches approx: {len(train_loader)}\")\nprint(f\"Dev loader batches approx: {len(dev_loader)}\")\nprint(f\"Eval loader batches approx: {len(eval_loader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:17:57.521929Z","iopub.execute_input":"2025-11-08T16:17:57.522204Z","iopub.status.idle":"2025-11-08T16:17:57.799379Z","shell.execute_reply.started":"2025-11-08T16:17:57.522183Z","shell.execute_reply":"2025-11-08T16:17:57.798547Z"},"id":"PyEAHwlAEMFi","outputId":"62d4dc07-fb39-45a5-bb6e-1f76612bcceb","colab":{"referenced_widgets":["cfa6c846dccf44ca99b3ce50b0657fa0"]}},"outputs":[{"name":"stdout","text":"Initializing processor for facebook/wav2vec2-xls-r-300m...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"157c35d1d92b421ca7e6e857586d5b6d"}},"metadata":{}},{"name":"stdout","text":"Creating datasets...\nCreating data loaders...\nTrain loader batches approx: 626\nDev loader batches approx: 79\nEval loader batches approx: 79\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# --- 4. Model Definition ---\nclass XLSRClassificationModel(nn.Module):\n    \"\"\"XLS-R model (Wav2Vec2 architecture) with a classification head.\"\"\"\n    def __init__(self, model_identifier=MODEL_IDENTIFIER, num_labels=2, dropout_prob=0.1):\n        super().__init__()\n        print(f\"Loading pre-trained model: {model_identifier}\")\n        # Load the pretrained XLS-R base model using Wav2Vec2Model class\n        self.xlsr = Wav2Vec2Model.from_pretrained(model_identifier) # <<< Uses updated identifier\n\n        # --- Freeze the encoder initially ---\n        self.freeze_encoder() # Call freeze method here\n\n        # Get the hidden size from the model config\n        self.hidden_size = self.xlsr.config.hidden_size\n        print(f\"Model hidden size: {self.hidden_size}\")\n\n        # Define the classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(self.xlsr.config.hidden_size, 256),\n            nn.ReLU(),\n            nn.Dropout(dropout_prob),\n            nn.Linear(256, num_labels)\n        )\n        self.attention_weights_layer = nn.Sequential(\n            nn.Linear(self.hidden_size, 128), # Project hidden state\n            nn.Tanh(),                     # Activation\n            nn.Linear(128, 1)              # Output one score per time step\n        )\n        self.num_labels = num_labels\n\n    def freeze_encoder(self):\n        \"\"\"Freezes all layers in the feature encoder.\"\"\"\n        print(\"Freezing encoder layers...\")\n        if hasattr(self.xlsr, 'feature_extractor'): # Older Wav2Vec2 structure\n             for param in self.xlsr.feature_extractor.parameters():\n                 param.requires_grad = False\n        if hasattr(self.xlsr, 'feature_projection'): # Newer structure / Conv Layers\n             for param in self.xlsr.feature_projection.parameters():\n                 param.requires_grad = False\n        if hasattr(self.xlsr, 'encoder'): # Transformer blocks\n            for param in self.xlsr.encoder.parameters():\n                param.requires_grad = False\n        print(\"Encoder layers frozen.\")\n\n    def unfreeze_encoder(self, num_layers=None):\n        \"\"\"Unfreezes the top 'num_layers' of the transformer encoder.\"\"\"\n        if not hasattr(self.xlsr, 'encoder') or not hasattr(self.xlsr.encoder, 'layers'):\n             print(\"Warning: Model structure does not match expected 'encoder.layers'. Cannot unfreeze specific layers.\")\n             # Optionally unfreeze the whole encoder if structure is different\n             # for param in self.xlsr.encoder.parameters():\n             #    param.requires_grad = True\n             return\n\n        if num_layers is None: # Unfreeze all encoder layers\n            print(f\"Unfreezing ALL {len(self.xlsr.encoder.layers)} encoder layers...\")\n            for param in self.xlsr.encoder.parameters():\n                 param.requires_grad = True\n        elif num_layers > 0:\n             total_layers = len(self.xlsr.encoder.layers)\n             layers_to_unfreeze = min(num_layers, total_layers)\n             print(f\"Unfreezing the top {layers_to_unfreeze} encoder layers...\")\n             # Unfreeze the specified top layers\n             for i in range(total_layers - layers_to_unfreeze, total_layers):\n                 for param in self.xlsr.encoder.layers[i].parameters():\n                     param.requires_grad = True\n        else:\n             print(\"No encoder layers specified to unfreeze (num_layers=0 or None). Keeping frozen.\")\n\n        # Optional: Verify which layers are unfrozen\n        # for name, param in self.xlsr.encoder.named_parameters():\n        #     if param.requires_grad:\n        #         print(f\"  - Unfrozen: {name}\")\n\n\n    def forward(self, input_values, attention_mask=None):\n        # Pass data through base XLS-R model\n        outputs = self.xlsr(input_values=input_values, attention_mask=attention_mask)\n\n        # Use the hidden states from the last layer\n        last_hidden_state = outputs.last_hidden_state\n\n         # --- Replace Mean Pooling with Attention Pooling ---\n        # Calculate attention scores\n        attention_logits = self.attention_weights_layer(last_hidden_state).squeeze(-1) # Shape: [batch, seq_len]\n\n        # Apply mask before softmax (mask has 1 for real tokens, 0 for padding)\n        if attention_mask is not None:\n            # Set scores for padding tokens to a very large negative number\n            attention_logits = attention_logits.masked_fill(attention_mask == 0, -1e9)\n\n        # Calculate attention weights\n        attention_weights = nn.functional.softmax(attention_logits, dim=1) # Shape: [batch, seq_len]\n\n        # Calculate weighted sum (attention pooling)\n        # Unsqueeze weights to match hidden state dims for broadcasting: [batch, seq_len, 1]\n        pooled_output = torch.sum(last_hidden_state * attention_weights.unsqueeze(-1), dim=1)\n        # Shape: [batch, hidden_size]\n        # --- End Replacement ---\n\n\n        # Pass the pooled output through the classifier\n        logits = self.classifier(pooled_output)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:18:01.765329Z","iopub.execute_input":"2025-11-08T16:18:01.766239Z","iopub.status.idle":"2025-11-08T16:18:01.782999Z","shell.execute_reply.started":"2025-11-08T16:18:01.766204Z","shell.execute_reply":"2025-11-08T16:18:01.782176Z"},"id":"xXkxyjTtEMFi"},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# --- 5. EER Calculation ---\ndef calculate_eer(y_true, y_scores):\n    \"\"\"Calculates the Equal Error Rate (EER)\"\"\"\n    y_true = np.asarray(y_true)\n    y_scores = np.asarray(y_scores)\n    if len(np.unique(y_true)) < 2:\n        return float('nan'), float('nan')\n    fpr, tpr, thresholds = roc_curve(y_true, y_scores, pos_label=1)\n    fnr = 1 - tpr\n    eer_threshold_idx = np.nanargmin(np.abs(fpr - fnr))\n    if eer_threshold_idx < len(fpr) and eer_threshold_idx < len(fnr):\n        eer = (fpr[eer_threshold_idx] + fnr[eer_threshold_idx]) / 2.0\n        eer_threshold = thresholds[eer_threshold_idx]\n        return eer, eer_threshold\n    else:\n        print(\"Warning: Could not determine EER threshold index.\")\n        return float('nan'), float('nan')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:18:07.148997Z","iopub.execute_input":"2025-11-08T16:18:07.149280Z","iopub.status.idle":"2025-11-08T16:18:07.155187Z","shell.execute_reply.started":"2025-11-08T16:18:07.149257Z","shell.execute_reply":"2025-11-08T16:18:07.154369Z"},"id":"OSo9njqBEMFi"},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# --- 6. Training and Evaluation Functions ---\nfrom sklearn.metrics import roc_auc_score # Import AUC calculation\nimport sys\n# Remove dependency on asvspoof-toolkit support_measure\n\ndef calculate_eer(y_true, y_scores):\n    \"\"\"Calculates the Equal Error Rate (EER)\"\"\"\n    y_true = np.asarray(y_true)\n    y_scores = np.asarray(y_scores)\n    if len(np.unique(y_true)) < 2:\n        return float('nan'), float('nan')\n    fpr, tpr, thresholds = roc_curve(y_true, y_scores, pos_label=1)\n    fnr = 1 - tpr\n    eer_threshold_idx = np.nanargmin(np.abs(fpr - fnr))\n    if eer_threshold_idx < len(fpr) and eer_threshold_idx < len(fnr):\n        eer = (fpr[eer_threshold_idx] + fnr[eer_threshold_idx]) / 2.0\n        eer_threshold = thresholds[eer_threshold_idx]\n        return eer, eer_threshold\n    else:\n        print(\"Warning: Could not determine EER threshold index.\")\n        return float('nan'), float('nan')\n\ndef calculate_tdcf(y_true, y_scores, p_bona=0.5, p_spoof=0.5, c_miss=1, c_fa=1):\n    \"\"\"\n    Calculates the minimum t-DCF for a given set of scores and labels.\n    Implemented based on ASVspoof challenge evaluation plan.\n\n    Args:\n        y_true (np.ndarray): True labels (1 for bonafide, 0 for spoof).\n        y_scores (np.ndarray): Predicted scores (higher for bonafide).\n        p_bona (float): Prior probability of bonafide samples.\n        p_spoof (float): Prior probability of spoof samples.\n        c_miss (float): Cost of a miss (false rejection of bonafide).\n        c_fa (float): Cost of a false alarm (false acceptance of spoof).\n\n    Returns:\n        float: The minimum t-DCF value.\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_scores = np.asarray(y_scores)\n\n    # Ensure there are both bonafide and spoof samples\n    if len(np.unique(y_true)) < 2:\n        print(\"Warning: Cannot calculate t-DCF - only one true class present.\")\n        return float('nan')\n\n    # Sort scores and corresponding labels\n    indices = np.argsort(y_scores)\n    y_scores_sorted = y_scores[indices]\n    y_true_sorted = y_true[indices]\n\n    n_bona = np.sum(y_true == 1)\n    n_spoof = np.sum(y_true == 0)\n\n    if n_bona == 0 or n_spoof == 0:\n         print(\"Warning: Cannot calculate t-DCF - no bonafide or no spoof samples.\")\n         return float('nan')\n\n    # Initialize t-DCF to a large value\n    min_tdcf = float('inf')\n\n    # Iterate through all possible thresholds (scores)\n    # Using unique sorted scores as potential thresholds\n    unique_scores = np.unique(y_scores_sorted)\n    for threshold in unique_scores:\n        # Classify samples based on the current threshold\n        # Samples with score >= threshold are predicted as bonafide (1)\n        # Samples with score < threshold are predicted as spoof (0)\n        y_pred = (y_scores_sorted >= threshold).astype(int)\n\n        # Calculate False Alarm Rate (FAR) and False Rejection Rate (FRR)\n        # FAR: Proportion of spoof samples incorrectly classified as bonafide (0 -> 1)\n        # FRR: Proportion of bonafide samples incorrectly classified as spoof (1 -> 0)\n        fa = np.sum((y_true_sorted == 0) & (y_pred == 1))\n        miss = np.sum((y_true_sorted == 1) & (y_pred == 0))\n\n        far = fa / n_spoof\n        frr = miss / n_bona\n\n        # Calculate t-DCF for the current threshold\n        tdcf = c_miss * frr * p_bona + c_fa * far * p_spoof\n\n        # Update minimum t-DCF\n        if tdcf < min_tdcf:\n            min_tdcf = tdcf\n\n    # Normalize minimum t-DCF by the minimum possible t-DCF\n    # The minimum possible t-DCF is achieved by a perfect system (FAR=0, FRR=0)\n    # Normalized t-DCF = min_tdcf / min(c_miss * p_bona, c_fa * p_spoof)\n    # A perfect system would have costs: c_miss * 0 * p_bona + c_fa * 0 * p_spoof = 0\n    # However, the standard normalization is against a system that always outputs bonafide or always outputs spoof.\n    # The denominator is min(c_miss * p_bona, c_fa * p_spoof)\n    denominator = min(c_miss * p_bona, c_fa * p_spoof)\n    if denominator == 0:\n         print(\"Warning: Denominator for normalized t-DCF is zero. Returning unnormalized t-DCF.\")\n         return min_tdcf # Return unnormalized if denominator is zero\n\n    normalized_min_tdcf = min_tdcf / denominator\n\n    return normalized_min_tdcf\n\n\ndef evaluate(model, data_loader, criterion, device, return_tdcf=False): # Removed tdcf file paths\n    \"\"\"Evaluates the model on a given dataset.\"\"\"\n    model.eval()\n    total_loss = 0.0\n    num_samples = 0\n    printed_batch_info = False # Flag to print only for the first batch\n    with torch.no_grad():\n        all_preds_probs = [] # Store probabilities for AUC, EER, and t-DCF\n        all_labels = []\n        progress_bar = tqdm(data_loader, desc=\"Evaluating\", leave=False)\n        for i, batch in enumerate(progress_bar): # Add enumerate to track batch index\n            if batch is None: continue\n            input_values = batch[\"input_values\"].to(device, non_blocking=True)\n            labels = batch[\"labels\"].to(device, non_blocking=True).long()\n            if input_values.size(0) == 0: continue\n\n            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n                logits = model(input_values)\n                loss = criterion(logits, labels)\n            total_loss += loss.item() * input_values.size(0)\n            num_samples += input_values.size(0)\n            probabilities = torch.softmax(logits, dim=1)\n            # We need the score for the BONAFIDE class (label 1) for EER and t-DCF\n            positive_class_probs = probabilities[:, 1].cpu().numpy()\n            all_preds_probs.extend(positive_class_probs)\n            all_labels.extend(labels.cpu().numpy())\n\n            # --- Add Diagnostic Print ---\n            if not printed_batch_info and i == 0: # Print for the first batch only\n                print(\"\\n--- Evaluation Batch 0 Diagnostics ---\")\n                print(f\"Labels (first 10): {labels[:10].cpu().numpy()}\")\n                print(f\"Logits (first 5): \\n{logits[:5].cpu().numpy()}\")\n                print(f\"Probabilities (first 5): \\n{probabilities[:5].cpu().numpy()}\")\n                print(f\"Positive Class Probs (first 10): {positive_class_probs[:10]}\")\n                # Add predicted binary labels for the first batch\n                preds_binary_batch = (positive_class_probs > 0.5).astype(int)\n                print(f\"Predicted Binary (first 10): {preds_binary_batch[:10]}\")\n                print(\"--- End Diagnostics ---\")\n                printed_batch_info = True\n            # --- End Diagnostic Print ---\n\n\n    if num_samples == 0:\n        if return_tdcf:\n             return float('nan'), float('nan'), float('nan'), float('nan'), float('nan')\n        else:\n            return float('nan'), float('nan'), float('nan'), float('nan')\n\n    avg_loss = total_loss / num_samples\n    all_labels = np.array(all_labels)\n    all_preds_probs = np.array(all_preds_probs)\n\n    # Calculate EER\n    eer, _ = calculate_eer(all_labels, all_preds_probs)\n\n    # Calculate Accuracy (using a 0.5 threshold for binary prediction)\n    preds_binary = (all_preds_probs > 0.5).astype(int)\n    accuracy = np.mean(preds_binary == all_labels) if len(all_labels) > 0 else 0.0\n\n    # Calculate AUC\n    try:\n        if len(np.unique(all_labels)) > 1:\n             auc_score = roc_auc_score(all_labels, all_preds_probs)\n        else:\n             print(\"Warning: Cannot calculate AUC - only one true class present in evaluation data.\")\n             auc_score = float('nan')\n    except Exception as e:\n        print(f\"Error calculating AUC: {e}\")\n        auc_score = float('nan')\n\n    if return_tdcf:\n        # Calculate min t-DCF using the custom function\n        min_tdcf = calculate_tdcf(all_labels, all_preds_probs)\n        return avg_loss, accuracy, eer, auc_score, min_tdcf\n    else:\n        return avg_loss, accuracy, eer, auc_score\n\n\ndef train_epoch(model, data_loader, criterion, optimizer, scheduler, device, scaler):\n    \"\"\"Trains the model for one epoch.\"\"\"\n    model.train()\n    total_loss = 0.0\n    num_batches = 0\n    progress_bar = tqdm(data_loader, desc=\"Training\", leave=False)\n    for batch in progress_bar:\n        if batch is None: continue\n        input_values = batch[\"input_values\"].to(device, non_blocking=True)\n        labels = batch[\"labels\"].to(device, non_blocking=True).long()\n        if input_values.size(0) == 0: continue\n\n        optimizer.zero_grad()\n        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n            logits = model(input_values)\n            loss = criterion(logits, labels)\n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        scaler.step(optimizer)\n        scaler.update()\n        if scheduler: scheduler.step()\n\n        total_loss += loss.item()\n        num_batches += 1\n        progress_bar.set_postfix({'loss': loss.item()})\n\n    avg_loss = total_loss / num_batches if num_batches > 0 else 0.0\n    return avg_loss\n\n\ndef train_model(model, train_loader, dev_loader, eval_loader, criterion, optimizer, scheduler, device, epochs, model_save_path, patience, checkpoint_name):\n    \"\"\"Full training loop with evaluation, checkpointing, and early stopping.\"\"\"\n    best_val_eer = float('inf')\n    epochs_no_improve = 0\n    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_eer': [], 'val_auc': [], 'eval_loss': [], 'eval_acc': [], 'eval_eer': [], 'eval_auc': [], 'eval_min_tdcf': []} # Added eval metrics including t-DCF\n    best_model_filepath = os.path.join(model_save_path, checkpoint_name)\n\n    scaler = torch.amp.GradScaler('cuda')\n\n    # Define temporary files for t-DCF calculation during evaluation\n    # Removed temporary file paths as t-DCF is calculated directly\n\n\n    for epoch in range(epochs):\n        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler, device, scaler)\n        history['train_loss'].append(train_loss)\n        print(f\"Train Loss: {train_loss:.4f}\")\n\n        # Evaluate on Development Set\n        val_loss, val_acc, val_eer, val_auc = evaluate(model, dev_loader, criterion, device, return_tdcf=False) # No t-DCF on dev\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        history['val_eer'].append(val_eer)\n        history['val_auc'].append(val_auc)\n        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val EER: {val_eer:.4f}, Val AUC: {val_auc:.4f}\")\n\n        # Evaluate on Evaluation Set for t-DCF tracking\n        eval_loss, eval_acc, eval_eer, eval_auc, eval_min_tdcf = evaluate(\n            model, eval_loader, criterion, device,\n            return_tdcf=True,\n            # Removed tdcf file paths as t-DCF is calculated directly\n        )\n        history['eval_loss'].append(eval_loss)\n        history['eval_acc'].append(eval_acc)\n        history['eval_eer'].append(eval_eer)\n        history['eval_auc'].append(eval_auc)\n        history['eval_min_tdcf'].append(eval_min_tdcf)\n        print(f\"Eval Loss: {eval_loss:.4f}, Eval Acc: {eval_acc:.4f}, Eval EER: {eval_eer:.4f}, Eval AUC: {eval_auc:.4f}, Eval min t-DCF: {eval_min_tdcf:.4f}\") # Print t-DCF\n\n\n        # Early stopping based on Validation EER\n        if not np.isnan(val_eer) and val_eer < best_val_eer:\n            best_val_eer = val_eer\n            epochs_no_improve = 0\n            torch.save(model.state_dict(), best_model_filepath)\n            print(f\"Validation EER improved to {best_val_eer:.4f}. Saving model to {best_model_filepath}\")\n        elif not np.isnan(val_eer):\n            epochs_no_improve += 1\n            print(f\"Validation EER did not improve. ({epochs_no_improve}/{patience})\")\n        else:\n            print(\"Warning: Validation EER is NaN.\")\n\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n            break\n\n        gc.collect()\n        if device == torch.device(\"cuda\"): torch.cuda.empty_cache()\n\n    print(\"\\nTraining loop finished.\")\n    # Load the best model based on Val EER before returning history\n    if os.path.exists(best_model_filepath):\n        print(f\"Loading best model weights from {best_model_filepath}\")\n        try:\n             # Use weights_only=True for safety in future PyTorch versions\n             model.load_state_dict(torch.load(best_model_filepath, map_location=device, weights_only=True))\n        except Exception as e:\n            print(f\"Error loading best model weights: {e}. Continuing with current model state.\")\n    else:\n        print(f\"Warning: Best model file '{best_model_filepath}' not found.\")\n    return history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:18:10.763710Z","iopub.execute_input":"2025-11-08T16:18:10.764003Z","iopub.status.idle":"2025-11-08T16:18:10.791835Z","shell.execute_reply.started":"2025-11-08T16:18:10.763980Z","shell.execute_reply":"2025-11-08T16:18:10.791015Z"},"id":"yEKKpixwEMFj"},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# --- 7. Initialize Model, Optimizer, Loss, Scheduler ---\nprint(\"Initializing model...\")\n# <<< CHANGE: Using updated class name >>>\nmodel = XLSRClassificationModel(\n    model_identifier=MODEL_IDENTIFIER,\n).to(DEVICE)\n\nif class_weights is not None:\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    print(\"Using CrossEntropyLoss with calculated class weights.\")\nelse:\n    criterion = nn.CrossEntropyLoss()\n    print(\"Warning: Using CrossEntropyLoss without class weights (weights could not be calculated).\")\n\n# Optimizer should optimize all parameters if not frozen, or only requires_grad if frozen\n# Initially, only classifier head is unfrozen, so this is correct.\noptimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n# Need to calculate num_training_steps based on the actual train_loader length (full dataset)\nnum_training_steps = len(train_loader) * EPOCHS\nnum_warmup_steps = int(0.1 * num_training_steps)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:18:18.089851Z","iopub.execute_input":"2025-11-08T16:18:18.090626Z","iopub.status.idle":"2025-11-08T16:18:25.063399Z","shell.execute_reply.started":"2025-11-08T16:18:18.090579Z","shell.execute_reply":"2025-11-08T16:18:25.062652Z"},"id":"U6aXPTUfEMFj","outputId":"ac539077-244e-4860-9620-0a6e8acc5844","colab":{"referenced_widgets":["4e72620d60374c3d9e3d22bb56317fa3","3b620ebd9e6e4225b282633147d64a74","810ba850a0d244659414d5d88965e675"]}},"outputs":[{"name":"stdout","text":"Initializing model...\nLoading pre-trained model: facebook/wav2vec2-xls-r-300m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"676fba55c5a74001858a7dd4565c6dc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fead74990520480db1eed1ee73ca023b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80583938b04b4af3ad10ae0b1a60fc11"}},"metadata":{}},{"name":"stdout","text":"Freezing encoder layers...\nEncoder layers frozen.\nModel hidden size: 1024\nUsing CrossEntropyLoss with calculated class weights.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# --- 8. Initial Training (Train Classifier Head) ---\nprint(\"\\n--- Starting Initial Training (Train Classifier Head Only) ---\")\n# Pass the eval_loader to train_model\nhistory = train_model(\n    model, train_loader, dev_loader, eval_loader, criterion, optimizer, scheduler, DEVICE,\n    EPOCHS, MODEL_SAVE_PATH, EARLY_STOPPING_PATIENCE,\n    checkpoint_name=\"xlsr_initial_best.pt\" # Updated checkpoint name\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:18:45.027557Z","iopub.execute_input":"2025-11-08T16:18:45.028263Z","iopub.status.idle":"2025-11-08T19:12:32.896749Z","shell.execute_reply.started":"2025-11-08T16:18:45.028232Z","shell.execute_reply":"2025-11-08T19:12:32.895804Z"},"id":"XN1VDuHFEMFj","outputId":"febe2393-d3d5-4a7a-96ca-2c59f05bf251","colab":{"referenced_widgets":[""]}},"outputs":[{"name":"stdout","text":"\n--- Starting Initial Training (Train Classifier Head Only) ---\n\nEpoch 1/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.6769\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[0.10754 0.06006]\n [0.1288  0.04144]\n [0.00971 0.1259 ]\n [0.01444 0.1311 ]\n [0.1183  0.05048]]\nProbabilities (first 5): \n[[0.5117 0.488 ]\n [0.522  0.4783]\n [0.471  0.529 ]\n [0.471  0.5293]\n [0.517  0.4832]]\nPositive Class Probs (first 10): [0.488  0.4783 0.529  0.5293 0.4832 0.517  0.493  0.5083 0.5146 0.4792]\nPredicted Binary (first 10): [0 0 1 1 0 1 0 1 1 0]\n--- End Diagnostics ---\nVal Loss: 0.7242, Val Acc: 0.3269, Val EER: 0.2729, Val AUC: 0.8328\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-0.0741   0.2024 ]\n [-0.0823   0.2102 ]\n [ 0.04486  0.1173 ]\n [-0.0479   0.1882 ]\n [-0.0709   0.2007 ]]\nProbabilities (first 5): \n[[0.4314 0.569 ]\n [0.4275 0.5728]\n [0.482  0.518 ]\n [0.4412 0.5586]\n [0.4326 0.5674]]\nPositive Class Probs (first 10): [0.569  0.5728 0.518  0.5586 0.5674 0.588  0.5796 0.554  0.559  0.563 ]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 0.7171, Eval Acc: 0.3394, Eval EER: 0.2055, Eval AUC: 0.8763, Eval min t-DCF: 0.4087\nValidation EER improved to 0.2729. Saving model to /kaggle/working/xlsr_initial_best.pt\n\nEpoch 2/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.5741\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[-0.797   1.143 ]\n [-0.6104  0.9775]\n [-0.535   0.826 ]\n [-0.827   1.128 ]\n [-0.565   0.9233]]\nProbabilities (first 5): \n[[0.1257 0.8745]\n [0.1697 0.83  ]\n [0.204  0.796 ]\n [0.124  0.876 ]\n [0.1842 0.816 ]]\nPositive Class Probs (first 10): [0.8745 0.83   0.796  0.876  0.816  0.8716 0.866  0.716  0.865  0.8765]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nVal Loss: 1.5953, Val Acc: 0.1071, Val EER: 0.2274, Val AUC: 0.8616\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-0.857  1.11 ]\n [-1.003  1.284]\n [-0.962  1.278]\n [-0.947  1.243]\n [-1.057  1.372]]\nProbabilities (first 5): \n[[0.1227  0.8774 ]\n [0.0922  0.9077 ]\n [0.0962  0.904  ]\n [0.10065 0.8994 ]\n [0.081   0.919  ]]\nPositive Class Probs (first 10): [0.8774 0.9077 0.904  0.8994 0.919  0.918  0.916  0.861  0.907  0.814 ]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 1.7101, Eval Acc: 0.1047, Eval EER: 0.2760, Eval AUC: 0.7901, Eval min t-DCF: 0.5315\nValidation EER improved to 0.2274. Saving model to /kaggle/working/xlsr_initial_best.pt\n\nEpoch 3/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.4978\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[-0.7446  0.9526]\n [-0.5874  0.816 ]\n [-0.87    1.052 ]\n [-0.7515  0.9355]\n [-0.6313  0.8535]]\nProbabilities (first 5): \n[[0.1548 0.845 ]\n [0.1973 0.8027]\n [0.1277 0.8726]\n [0.1561 0.8438]\n [0.1847 0.8154]]\nPositive Class Probs (first 10): [0.845  0.8027 0.8726 0.8438 0.8154 0.8667 0.8403 0.8125 0.871  0.8384]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nVal Loss: 1.5935, Val Acc: 0.1199, Val EER: 0.1510, Val AUC: 0.9264\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-0.9746  1.13  ]\n [-1.198   1.374 ]\n [-0.9805  1.17  ]\n [-1.219   1.387 ]\n [-1.351   1.539 ]]\nProbabilities (first 5): \n[[0.10864 0.891  ]\n [0.0709  0.929  ]\n [0.1043  0.8955 ]\n [0.0688  0.931  ]\n [0.05267 0.9473 ]]\nPositive Class Probs (first 10): [0.891  0.929  0.8955 0.931  0.9473 0.9243 0.934  0.879  0.922  0.8115]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 1.6497, Eval Acc: 0.1071, Eval EER: 0.1351, Eval AUC: 0.9311, Eval min t-DCF: 0.2366\nValidation EER improved to 0.1510. Saving model to /kaggle/working/xlsr_initial_best.pt\n\nEpoch 4/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3832\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[-0.5845  0.8965]\n [-0.1963  0.538 ]\n [-0.418   0.7095]\n [-0.7666  1.026 ]\n [-0.2104  0.5557]]\nProbabilities (first 5): \n[[0.1853 0.815 ]\n [0.3242 0.676 ]\n [0.2446 0.7554]\n [0.1427 0.8574]\n [0.3174 0.6826]]\nPositive Class Probs (first 10): [0.815  0.676  0.7554 0.8574 0.6826 0.842  0.794  0.6885 0.852  0.8135]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nVal Loss: 1.4433, Val Acc: 0.1823, Val EER: 0.1629, Val AUC: 0.9159\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-1.111   1.339 ]\n [-1.277   1.527 ]\n [-0.9976  1.281 ]\n [-1.255   1.503 ]\n [-1.38    1.641 ]]\nProbabilities (first 5): \n[[0.0794  0.9204 ]\n [0.05707 0.943  ]\n [0.0929  0.907  ]\n [0.05966 0.9404 ]\n [0.0465  0.9536 ]]\nPositive Class Probs (first 10): [0.9204 0.943  0.907  0.9404 0.9536 0.9404 0.9624 0.8804 0.95   0.8486]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 1.5423, Eval Acc: 0.1332, Eval EER: 0.1704, Eval AUC: 0.9023, Eval min t-DCF: 0.3371\nValidation EER did not improve. (1/5)\n\nEpoch 5/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3799\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[ 0.9946 -0.647 ]\n [ 1.2705 -0.903 ]\n [ 0.675  -0.3333]\n [ 0.555  -0.2617]\n [ 1.32   -0.938 ]]\nProbabilities (first 5): \n[[0.838   0.1622 ]\n [0.898   0.1022 ]\n [0.7324  0.2673 ]\n [0.6934  0.3064 ]\n [0.9053  0.09467]]\nPositive Class Probs (first 10): [0.1622  0.1022  0.2673  0.3064  0.09467 0.2734  0.1251  0.1731  0.2189\n 0.1902 ]\nPredicted Binary (first 10): [0 0 0 0 0 0 0 0 0 0]\n--- End Diagnostics ---\nVal Loss: 0.3393, Val Acc: 0.8849, Val EER: 0.1091, Val AUC: 0.9592\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-0.2942   0.5405 ]\n [-0.4585   0.731  ]\n [ 0.2764   0.02887]\n [-0.3103   0.5835 ]\n [-0.372    0.676  ]]\nProbabilities (first 5): \n[[0.3027 0.6973]\n [0.2334 0.7666]\n [0.5615 0.4385]\n [0.2903 0.7095]\n [0.2595 0.74  ]]\nPositive Class Probs (first 10): [0.6973 0.7666 0.4385 0.7095 0.74   0.7305 0.8306 0.604  0.7266 0.618 ]\nPredicted Binary (first 10): [1 1 0 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 0.3626, Eval Acc: 0.8866, Eval EER: 0.1152, Eval AUC: 0.9550, Eval min t-DCF: 0.2231\nValidation EER improved to 0.1091. Saving model to /kaggle/working/xlsr_initial_best.pt\n\nEpoch 6/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3719\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[ 0.978  -0.4436]\n [ 1.232  -0.6753]\n [ 0.9004 -0.4534]\n [ 0.64   -0.1682]\n [ 1.343  -0.7793]]\nProbabilities (first 5): \n[[0.8057 0.1945]\n [0.8706 0.1293]\n [0.795  0.2052]\n [0.692  0.3083]\n [0.893  0.107 ]]\nPositive Class Probs (first 10): [0.1945 0.1293 0.2052 0.3083 0.107  0.353  0.12   0.1608 0.2079 0.2427]\nPredicted Binary (first 10): [0 0 0 0 0 0 0 0 0 0]\n--- End Diagnostics ---\nVal Loss: 0.3404, Val Acc: 0.8697, Val EER: 0.0784, Val AUC: 0.9719\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-0.4707   0.828  ]\n [-0.764    1.124  ]\n [ 0.11755  0.3428 ]\n [-0.536    0.9126 ]\n [-0.539    0.927  ]]\nProbabilities (first 5): \n[[0.2144 0.7856]\n [0.1315 0.8687]\n [0.4438 0.556 ]\n [0.1902 0.8096]\n [0.1876 0.8125]]\nPositive Class Probs (first 10): [0.7856 0.8687 0.556  0.8096 0.8125 0.771  0.9165 0.703  0.819  0.698 ]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 0.3850, Eval Acc: 0.8557, Eval EER: 0.1000, Eval AUC: 0.9681, Eval min t-DCF: 0.1841\nValidation EER improved to 0.0784. Saving model to /kaggle/working/xlsr_initial_best.pt\n\nEpoch 7/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3772\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[ 1.65   -1.213 ]\n [ 1.682  -1.242 ]\n [ 0.8506 -0.5522]\n [ 1.251  -0.8784]\n [ 1.838  -1.381 ]]\nProbabilities (first 5): \n[[0.946   0.054  ]\n [0.949   0.051  ]\n [0.8027  0.1974 ]\n [0.8936  0.10626]\n [0.9614  0.03845]]\nPositive Class Probs (first 10): [0.054   0.051   0.1974  0.10626 0.03845 0.1232  0.02563 0.1416  0.0702\n 0.05014]\nPredicted Binary (first 10): [0 0 0 0 0 0 0 0 0 0]\n--- End Diagnostics ---\nVal Loss: 0.2335, Val Acc: 0.9384, Val EER: 0.1068, Val AUC: 0.9642\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-0.2812  0.5244]\n [-0.4688  0.712 ]\n [ 0.6904 -0.3315]\n [-0.1215  0.3848]\n [-0.2915  0.5493]]\nProbabilities (first 5): \n[[0.3088 0.6914]\n [0.235  0.765 ]\n [0.7354 0.2646]\n [0.376  0.624 ]\n [0.3013 0.6987]]\nPositive Class Probs (first 10): [0.6914 0.765  0.2646 0.624  0.6987 0.755  0.7715 0.6665 0.573  0.6567]\nPredicted Binary (first 10): [1 1 0 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 0.2545, Eval Acc: 0.9239, Eval EER: 0.1065, Eval AUC: 0.9554, Eval min t-DCF: 0.2058\nValidation EER did not improve. (1/5)\n\nEpoch 8/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3606\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[ 0.758  -0.5254]\n [ 0.6543 -0.4304]\n [ 0.4473 -0.2798]\n [ 0.707  -0.5176]\n [ 0.905  -0.663 ]]\nProbabilities (first 5): \n[[0.783  0.217 ]\n [0.7476 0.2527]\n [0.6743 0.326 ]\n [0.773  0.2272]\n [0.8276 0.1725]]\nPositive Class Probs (first 10): [0.217  0.2527 0.326  0.2272 0.1725 0.4336 0.0843 0.3132 0.2043 0.2358]\nPredicted Binary (first 10): [0 0 0 0 0 0 0 0 0 0]\n--- End Diagnostics ---\nVal Loss: 0.3952, Val Acc: 0.8409, Val EER: 0.0311, Val AUC: 0.9946\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-0.8994  0.9824]\n [-1.075   1.165 ]\n [-0.4246  0.5938]\n [-0.73    0.835 ]\n [-0.87    0.9717]]\nProbabilities (first 5): \n[[0.1322 0.8677]\n [0.0962 0.904 ]\n [0.2654 0.735 ]\n [0.173  0.827 ]\n [0.1368 0.8633]]\nPositive Class Probs (first 10): [0.8677 0.904  0.735  0.827  0.8633 0.8687 0.8813 0.8774 0.781  0.8213]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 0.4591, Eval Acc: 0.7867, Eval EER: 0.0534, Eval AUC: 0.9905, Eval min t-DCF: 0.0887\nValidation EER improved to 0.0311. Saving model to /kaggle/working/xlsr_initial_best.pt\n\nEpoch 9/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3546\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bb71b616c2f4a038c881ebeb26daa94"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[-0.6914  0.8423]\n [-0.4312  0.5938]\n [-0.961   1.095 ]\n [-1.05    1.158 ]\n [-0.3186  0.4897]]\nProbabilities (first 5): \n[[0.1775  0.8228 ]\n [0.2642  0.736  ]\n [0.11346 0.8867 ]\n [0.09906 0.901  ]\n [0.3083  0.692  ]]\nPositive Class Probs (first 10): [0.8228 0.736  0.8867 0.901  0.692  0.9307 0.582  0.867  0.817  0.823 ]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nVal Loss: 1.8527, Val Acc: 0.2078, Val EER: 0.0609, Val AUC: 0.9856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f2ff21a1836498bb2cd45257188560e"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-2.709  2.734]\n [-2.908  2.926]\n [-1.912  2.008]\n [-2.512  2.553]\n [-2.502  2.553]]\nProbabilities (first 5): \n[[0.004307 0.9956  ]\n [0.002918 0.997   ]\n [0.01945  0.9805  ]\n [0.00628  0.9937  ]\n [0.00634  0.9937  ]]\nPositive Class Probs (first 10): [0.9956 0.997  0.9805 0.9937 0.9937 0.994  0.9976 0.995  0.993  0.995 ]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 2.0500, Eval Acc: 0.1618, Eval EER: 0.0722, Eval AUC: 0.9831, Eval min t-DCF: 0.1335\nValidation EER did not improve. (1/5)\n\nEpoch 10/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3457\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[-0.5024  0.7256]\n [-0.3586  0.5913]\n [-0.7886  0.951 ]\n [-0.6665  0.847 ]\n [-0.1799  0.421 ]]\nProbabilities (first 5): \n[[0.2266 0.7734]\n [0.2788 0.721 ]\n [0.1493 0.8506]\n [0.1804 0.82  ]\n [0.3542 0.646 ]]\nPositive Class Probs (first 10): [0.7734 0.721  0.8506 0.82   0.646  0.9297 0.371  0.8315 0.766  0.78  ]\nPredicted Binary (first 10): [1 1 1 1 1 1 0 1 1 1]\n--- End Diagnostics ---\nVal Loss: 1.5731, Val Acc: 0.2662, Val EER: 0.0451, Val AUC: 0.9919\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-2.668  2.75 ]\n [-2.996  3.068]\n [-2.031  2.166]\n [-2.596  2.686]\n [-2.53   2.623]]\nProbabilities (first 5): \n[[0.004417 0.9956  ]\n [0.00232  0.9976  ]\n [0.01482  0.9854  ]\n [0.005062 0.995   ]\n [0.005753 0.994   ]]\nPositive Class Probs (first 10): [0.9956 0.9976 0.9854 0.995  0.994  0.9937 0.998  0.996  0.993  0.9937]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 1.8143, Eval Acc: 0.2094, Eval EER: 0.0638, Eval AUC: 0.9900, Eval min t-DCF: 0.1067\nValidation EER did not improve. (2/5)\n\nEpoch 11/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3416\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[ 0.6807 -0.329 ]\n [ 0.752  -0.3948]\n [ 0.1357  0.1538]\n [ 0.6357 -0.315 ]\n [ 0.9175 -0.5527]]\nProbabilities (first 5): \n[[0.733  0.267 ]\n [0.759  0.2411]\n [0.4956 0.5044]\n [0.721  0.2788]\n [0.813  0.1869]]\nPositive Class Probs (first 10): [0.267   0.2411  0.5044  0.2788  0.1869  0.65    0.03525 0.373   0.2664\n 0.296  ]\nPredicted Binary (first 10): [0 0 1 0 0 1 0 0 0 0]\n--- End Diagnostics ---\nVal Loss: 0.5475, Val Acc: 0.7018, Val EER: 0.0311, Val AUC: 0.9953\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-1.933  2.094]\n [-2.326  2.475]\n [-1.324  1.537]\n [-1.826  1.989]\n [-1.809  1.984]]\nProbabilities (first 5): \n[[0.01753  0.9824  ]\n [0.008156 0.9917  ]\n [0.0541   0.946   ]\n [0.02156  0.9785  ]\n [0.02203  0.978   ]]\nPositive Class Probs (first 10): [0.9824 0.9917 0.946  0.9785 0.978  0.9644 0.9927 0.9873 0.968  0.9756]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 0.7138, Eval Acc: 0.5956, Eval EER: 0.0465, Eval AUC: 0.9923, Eval min t-DCF: 0.0845\nValidation EER did not improve. (3/5)\n\nEpoch 12/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.2998\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[-0.4897  0.7793]\n [-0.257   0.5625]\n [-1.416   1.623 ]\n [-0.702   0.941 ]\n [-0.289   0.5874]]\nProbabilities (first 5): \n[[0.2194 0.781 ]\n [0.306  0.6943]\n [0.0457 0.954 ]\n [0.162  0.838 ]\n [0.294  0.706 ]]\nPositive Class Probs (first 10): [0.781  0.6943 0.954  0.838  0.706  0.9624 0.2103 0.9014 0.822  0.7656]\nPredicted Binary (first 10): [1 1 1 1 1 1 0 1 1 1]\n--- End Diagnostics ---\nVal Loss: 1.8790, Val Acc: 0.2838, Val EER: 0.0324, Val AUC: 0.9941\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-3.48   3.596]\n [-3.87   3.965]\n [-2.684  2.867]\n [-3.387  3.508]\n [-3.395  3.527]]\nProbabilities (first 5): \n[[8.445e-04 9.990e-01]\n [3.958e-04 9.995e-01]\n [3.870e-03 9.961e-01]\n [1.012e-03 9.990e-01]\n [9.851e-04 9.990e-01]]\nPositive Class Probs (first 10): [0.999  0.9995 0.996  0.999  0.999  0.9985 0.9995 0.9995 0.9985 0.999 ]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 2.2203, Eval Acc: 0.2363, Eval EER: 0.0565, Eval AUC: 0.9901, Eval min t-DCF: 0.0993\nValidation EER did not improve. (4/5)\n\nEpoch 13/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3166\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[-0.04105  0.3303 ]\n [ 0.2034   0.09973]\n [-1.021    1.23   ]\n [-0.03247  0.2927 ]\n [ 0.11017  0.1838 ]]\nProbabilities (first 5): \n[[0.4082  0.592  ]\n [0.526   0.474  ]\n [0.09515 0.905  ]\n [0.4194  0.5806 ]\n [0.4817  0.5186 ]]\nPositive Class Probs (first 10): [0.592   0.474   0.905   0.5806  0.5186  0.92    0.06616 0.761   0.637\n 0.606  ]\nPredicted Binary (first 10): [1 0 1 1 1 1 0 1 1 1]\n--- End Diagnostics ---\nVal Loss: 1.2683, Val Acc: 0.4197, Val EER: 0.0298, Val AUC: 0.9962\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-3.209  3.33 ]\n [-3.672  3.775]\n [-2.613  2.79 ]\n [-3.148  3.27 ]\n [-3.203  3.336]]\nProbabilities (first 5): \n[[1.444e-03 9.985e-01]\n [5.827e-04 9.995e-01]\n [4.486e-03 9.956e-01]\n [1.629e-03 9.985e-01]\n [1.444e-03 9.985e-01]]\nPositive Class Probs (first 10): [0.9985 0.9995 0.9956 0.9985 0.9985 0.9966 0.9995 0.9995 0.997  0.998 ]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 1.6109, Eval Acc: 0.3521, Eval EER: 0.0465, Eval AUC: 0.9930, Eval min t-DCF: 0.0868\nValidation EER improved to 0.0298. Saving model to /kaggle/working/xlsr_initial_best.pt\n\nEpoch 14/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3438\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[-0.02301  0.3147 ]\n [ 0.2402   0.0656 ]\n [-1.064    1.299  ]\n [-0.1633   0.4292 ]\n [ 0.05414  0.239  ]]\nProbabilities (first 5): \n[[0.4163 0.5835]\n [0.5435 0.4565]\n [0.086  0.914 ]\n [0.356  0.644 ]\n [0.4539 0.546 ]]\nPositive Class Probs (first 10): [0.5835  0.4565  0.914   0.644   0.546   0.932   0.06015 0.742   0.6523\n 0.5986 ]\nPredicted Binary (first 10): [1 0 1 1 1 1 0 1 1 1]\n--- End Diagnostics ---\nVal Loss: 1.3943, Val Acc: 0.3877, Val EER: 0.0246, Val AUC: 0.9969\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-3.344  3.488]\n [-3.82   3.947]\n [-2.902  3.096]\n [-3.38   3.516]\n [-3.438  3.586]]\nProbabilities (first 5): \n[[1.078e-03 9.990e-01]\n [4.230e-04 9.995e-01]\n [2.478e-03 9.976e-01]\n [1.010e-03 9.990e-01]\n [8.898e-04 9.990e-01]]\nPositive Class Probs (first 10): [0.999  0.9995 0.9976 0.999  0.999  0.9976 0.9995 0.9995 0.998  0.9985]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 1.7277, Eval Acc: 0.3505, Eval EER: 0.0374, Eval AUC: 0.9939, Eval min t-DCF: 0.0703\nValidation EER improved to 0.0246. Saving model to /kaggle/working/xlsr_initial_best.pt\n\nEpoch 15/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.2869\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[ 0.0585   0.2258 ]\n [ 0.3704  -0.07056]\n [-0.9673   1.2    ]\n [ 0.03568  0.2266 ]\n [ 0.134    0.1519 ]]\nProbabilities (first 5): \n[[0.4583 0.5415]\n [0.6084 0.3916]\n [0.1027 0.8975]\n [0.4524 0.5474]\n [0.4956 0.5044]]\nPositive Class Probs (first 10): [0.5415  0.3916  0.8975  0.5474  0.5044  0.9106  0.04272 0.66    0.581\n 0.5576 ]\nPredicted Binary (first 10): [1 0 1 1 1 1 0 1 1 1]\n--- End Diagnostics ---\nVal Loss: 1.2043, Val Acc: 0.4460, Val EER: 0.0228, Val AUC: 0.9973\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-3.287  3.432]\n [-3.762  3.887]\n [-2.979  3.168]\n [-3.318  3.451]\n [-3.45   3.592]]\nProbabilities (first 5): \n[[1.206e-03 9.990e-01]\n [4.766e-04 9.995e-01]\n [2.136e-03 9.980e-01]\n [1.147e-03 9.990e-01]\n [8.745e-04 9.990e-01]]\nPositive Class Probs (first 10): [0.999  0.9995 0.998  0.999  0.999  0.997  0.9995 0.9995 0.9976 0.998 ]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 1.5497, Eval Acc: 0.3791, Eval EER: 0.0387, Eval AUC: 0.9951, Eval min t-DCF: 0.0630\nValidation EER improved to 0.0228. Saving model to /kaggle/working/xlsr_initial_best.pt\n\nTraining loop finished.\nLoading best model weights from /kaggle/working/xlsr_initial_best.pt\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# --- 9. Fine-tuning ---\nprint(\"\\n--- Starting Fine-tuning ---\")\n# Unfreeze encoder layers (e.g., last 8)\nmodel.unfreeze_encoder(num_layers=8)\nmodel.to(DEVICE) # Ensure model is on correct device\n\n# Optimizer for fine-tuning (includes newly unfrozen layers)\n# Need to re-create optimizer to include newly unfrozen layers\noptimizer_ft = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=FINETUNE_LR)\n# Need to calculate num_training_steps based on the actual train_loader length (full dataset)\nnum_training_steps_ft = len(train_loader) * FINETUNE_EPOCHS\nnum_warmup_steps_ft = int(0.1 * num_training_steps_ft)\nscheduler_ft = get_linear_schedule_with_warmup(optimizer_ft, num_warmup_steps=num_warmup_steps_ft, num_training_steps=num_training_steps_ft)\n\n# Fine-tune the model\n# Pass the eval_loader to train_model\nhistory_ft = train_model(\n    model, train_loader, dev_loader, eval_loader, criterion, optimizer_ft, scheduler_ft, DEVICE,\n    FINETUNE_EPOCHS, MODEL_SAVE_PATH, EARLY_STOPPING_PATIENCE,\n    checkpoint_name=BEST_MODEL_NAME # Save overall best fine-tuned model\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T19:12:48.206891Z","iopub.execute_input":"2025-11-08T19:12:48.207712Z","iopub.status.idle":"2025-11-08T19:51:22.041319Z","shell.execute_reply.started":"2025-11-08T19:12:48.207678Z","shell.execute_reply":"2025-11-08T19:51:22.040631Z"},"id":"O26SSQiSEMFj","colab":{"referenced_widgets":[""]},"outputId":"6ea45b22-3ac4-49f0-a007-fbb055f97237"},"outputs":[{"name":"stdout","text":"\n--- Starting Fine-tuning ---\nUnfreezing the top 8 encoder layers...\n\nEpoch 1/3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.5260\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[ 7.12    -6.625  ]\n [ 6.53    -6.066  ]\n [ 0.1294   0.09796]\n [ 3.113   -2.787  ]\n [ 3.54    -3.182  ]]\nProbabilities (first 5): \n[[1.0000e+00 1.0729e-06]\n [1.0000e+00 3.3975e-06]\n [5.0781e-01 4.9219e-01]\n [9.9707e-01 2.7313e-03]\n [9.9902e-01 1.2045e-03]]\nPositive Class Probs (first 10): [1.0729e-06 3.3975e-06 4.9219e-01 2.7313e-03 1.2045e-03 1.5251e-02\n 0.0000e+00 7.4863e-05 8.5205e-01 3.3188e-03]\nPredicted Binary (first 10): [0 0 0 0 0 0 0 0 1 0]\n--- End Diagnostics ---\nVal Loss: 1.3498, Val Acc: 0.7842, Val EER: 0.0348, Val AUC: 0.9652\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-11.984  11.8  ]\n [-10.836  10.68 ]\n [-11.21   11.08 ]\n [-11.88   11.69 ]\n [-11.56   11.39 ]]\nProbabilities (first 5): \n[[0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]]\nPositive Class Probs (first 10): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 3.3479, Eval Acc: 0.5995, Eval EER: 0.1105, Eval AUC: 0.8895, Eval min t-DCF: 0.2210\nValidation EER improved to 0.0348. Saving model to /kaggle/working/wav2vec2_deepfake_best.pt\n\nEpoch 2/3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3645\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[ 15.74  -14.98 ]\n [ 14.29  -13.586]\n [  8.97   -8.46 ]\n [ 10.67  -10.11 ]\n [ 11.22  -10.63 ]]\nProbabilities (first 5): \n[[1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\nPositive Class Probs (first 10): [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 6.e-08 0.e+00]\nPredicted Binary (first 10): [0 0 0 0 0 0 0 0 0 0]\n--- End Diagnostics ---\nVal Loss: 0.4892, Val Acc: 0.9504, Val EER: 0.0125, Val AUC: 0.9875\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-20.58  20.22]\n [-17.25  16.98]\n [-14.7   14.52]\n [-17.11  16.84]\n [-18.45  18.17]]\nProbabilities (first 5): \n[[0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]]\nPositive Class Probs (first 10): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 2.9426, Eval Acc: 0.7637, Eval EER: 0.0844, Eval AUC: 0.9156, Eval min t-DCF: 0.1689\nValidation EER improved to 0.0125. Saving model to /kaggle/working/wav2vec2_deepfake_best.pt\n\nEpoch 3/3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/626 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.2800\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[ 18.45  -17.6  ]\n [ 16.56  -15.766]\n [ 12.01  -11.39 ]\n [ 12.766 -12.16 ]\n [ 14.19  -13.51 ]]\nProbabilities (first 5): \n[[1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\nPositive Class Probs (first 10): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\nPredicted Binary (first 10): [0 0 0 0 0 0 0 0 0 0]\n--- End Diagnostics ---\nVal Loss: 0.4105, Val Acc: 0.9640, Val EER: 0.0116, Val AUC: 0.9884\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-22.23  21.83]\n [-18.3   18.  ]\n [-15.41  15.23]\n [-17.97  17.69]\n [-20.14  19.8 ]]\nProbabilities (first 5): \n[[0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]]\nPositive Class Probs (first 10): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 2.6960, Eval Acc: 0.7954, Eval EER: 0.0747, Eval AUC: 0.9253, Eval min t-DCF: 0.1494\nValidation EER improved to 0.0116. Saving model to /kaggle/working/wav2vec2_deepfake_best.pt\n\nTraining loop finished.\nLoading best model weights from /kaggle/working/wav2vec2_deepfake_best.pt\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# --- 10. Final Evaluation ---\nprint(\"\\n--- Final Evaluation (Best Fine-tuned Model) ---\")\n\n# --- User Input for Model File Path to Evaluate ---\n# REPLACE THIS with the actual path to the model file you want to evaluate (.pt or .pth)\n# If you want to evaluate the best model saved during the fine-tuning, use BEST_MODEL_NAME.\n# If you want to evaluate the final saved model, use FINAL_MODEL_NAME.\n# If you want to evaluate a different model, provide its full path.\n# Default to the best fine-tuned model saved during the fine-tuning stage\nmodel_file_to_evaluate = os.path.join(MODEL_SAVE_PATH, BEST_MODEL_NAME)\n\nprint(f\"Attempting to evaluate model from: {model_file_to_evaluate}\")\n\n# Re-initialize the model architecture to match the saved state_dict\n# This assumes the same model class (XLSRClassificationModel) and parameters (MODEL_IDENTIFIER)\ntry:\n    # Assuming XLSRClassificationModel and MODEL_IDENTIFIER are defined in previous cells\n    model_for_evaluation = XLSRClassificationModel(\n        model_identifier=MODEL_IDENTIFIER,\n    ).to(DEVICE)\n    # Unfreeze layers as needed based on how the saved model was trained\n    # For this example, we assume it was fine-tuned with 8 layers unfrozen\n    model_for_evaluation.unfreeze_encoder(num_layers=8) # ADJUST THIS NUMBER if fine-tuning was different\n    model_for_evaluation.to(DEVICE)\n    print(\"Model architecture initialized for loading.\")\nexcept NameError:\n    print(\"Error: XLSRClassificationModel or MODEL_IDENTIFIER not defined. Please run previous cells.\")\n    model_for_evaluation = None\nexcept Exception as e:\n    print(f\"Error initializing model architecture for loading: {e}\")\n    model_for_evaluation = None\n\n\nif model_for_evaluation is not None and os.path.exists(model_file_to_evaluate):\n    try:\n        # Load the state dictionary\n        # Use map_location to ensure it loads correctly onto the current device (CPU or GPU)\n        # Use weights_only=True for safety in future PyTorch versions\n        model_for_evaluation.load_state_dict(torch.load(model_file_to_evaluate, map_location=DEVICE, weights_only=True))\n        print(f\"Successfully loaded model state dictionary from {model_file_to_evaluate}\")\n\n        # --- Evaluate the Loaded Model ---\n        print(\"\\n--- Evaluating the Loaded Model ---\")\n        # Assuming dev_loader, eval_loader, criterion, and DEVICE are defined in previous cells\n        if ('dev_loader' in locals() and dev_loader is not None and\n            'eval_loader' in locals() and eval_loader is not None and\n            'criterion' in locals() and criterion is not None):\n\n             print(\"\\nEvaluating on Development Set:\")\n             # Unpack 4 values including AUC (t-DCF removed)\n             dev_loss, dev_acc, dev_eer, dev_auc = evaluate(model_for_evaluation, dev_loader, criterion, DEVICE)\n             print(f\"Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_acc:.4f}, Dev EER: {dev_eer:.4f}, Dev AUC: {dev_auc:.4f}\")\n\n             print(\"\\nEvaluating on Evaluation Set:\")\n             # Unpack 5 values including AUC and min_tdcf\n             eval_loss, eval_acc, eval_eer, eval_auc, eval_min_tdcf = evaluate(\n                 model_for_evaluation, eval_loader, criterion, DEVICE,\n                 return_tdcf=True,\n                 # Removed tdcf file paths as t-DCF is calculated directly\n             )\n             print(f\"Eval Loss: {eval_loss:.4f}, Eval Acc: {eval_acc:.4f}, Eval EER: {eval_eer:.4f}, Eval AUC: {eval_auc:.4f}, Eval min t-DCF: {eval_min_tdcf:.4f}\")\n\n\n             # Optional: Generate Classification Report\n             # Note: Classification report does not directly use EER/t-DCF thresholds\n             if 'generate_report' in locals():\n                 print(\"\\nGenerating Classification Reports...\")\n                 # You might need to adapt generate_report to work with the loaded model_for_evaluation\n                 # Assuming generate_report takes model, data_loader, device, and name\n                 generate_report(model_for_evaluation, dev_loader, DEVICE, \"Loaded Model Dev\")\n                 generate_report(model_for_evaluation, eval_loader, DEVICE, \"Loaded Model Eval\")\n             else:\n                  print(\"Warning: generate_report function not found. Skipping classification reports.\")\n\n\n        else:\n            print(\"Error: Data loaders or criterion are not defined or are None. Cannot perform evaluation.\")\n\n\n    except Exception as e:\n        print(f\"Error loading model state dictionary or during evaluation: {e}\")\nelse:\n    if model_for_evaluation is None:\n        print(\"Error: Model architecture could not be initialized. Cannot load state dict.\")\n    elif not os.path.exists(model_file_to_evaluate):\n        print(f\"Error: Model file not found at {model_file_to_evaluate}. Please check the path.\")\n    else:\n        print(\"An unknown error occurred during model loading or evaluation setup.\")\n\n# Remove model_for_evaluation to free up memory if needed\n# del model_for_evaluation\n# if DEVICE.type == 'cuda': torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T19:52:03.469374Z","iopub.execute_input":"2025-11-08T19:52:03.469702Z","iopub.status.idle":"2025-11-08T19:53:23.053048Z","shell.execute_reply.started":"2025-11-08T19:52:03.469673Z","shell.execute_reply":"2025-11-08T19:53:23.052420Z"},"id":"-rNpoUtVEMFj","colab":{"referenced_widgets":[""]},"outputId":"e79ba74f-5bfd-4df8-c5d0-6a221ee0b096"},"outputs":[{"name":"stdout","text":"\n--- Final Evaluation (Best Fine-tuned Model) ---\nAttempting to evaluate model from: /kaggle/working/wav2vec2_deepfake_best.pt\nLoading pre-trained model: facebook/wav2vec2-xls-r-300m\nFreezing encoder layers...\nEncoder layers frozen.\nModel hidden size: 1024\nUnfreezing the top 8 encoder layers...\nModel architecture initialized for loading.\nSuccessfully loaded model state dictionary from /kaggle/working/wav2vec2_deepfake_best.pt\n\n--- Evaluating the Loaded Model ---\n\nEvaluating on Development Set:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 0 0 0 0 0]\nLogits (first 5): \n[[ 18.45  -17.6  ]\n [ 16.56  -15.766]\n [ 12.01  -11.39 ]\n [ 12.766 -12.16 ]\n [ 14.19  -13.51 ]]\nProbabilities (first 5): \n[[1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\nPositive Class Probs (first 10): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\nPredicted Binary (first 10): [0 0 0 0 0 0 0 0 0 0]\n--- End Diagnostics ---\nDev Loss: 0.4105, Dev Acc: 0.9640, Dev EER: 0.0116, Dev AUC: 0.9884\n\nEvaluating on Evaluation Set:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-22.23  21.83]\n [-18.3   18.  ]\n [-15.41  15.23]\n [-17.97  17.69]\n [-20.14  19.8 ]]\nProbabilities (first 5): \n[[0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]]\nPositive Class Probs (first 10): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nEval Loss: 2.6960, Eval Acc: 0.7954, Eval EER: 0.0747, Eval AUC: 0.9253, Eval min t-DCF: 0.1494\nWarning: generate_report function not found. Skipping classification reports.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# --- Evaluate on Full Original Data ---\nprint(\"\\n--- Evaluating on Full Original Data ---\")\n\n# Reload full protocols for evaluation\nprint(\"Loading full original protocols...\")\n\n# Assuming DATASET_PATH, AUDIO_DIRS, and PROTOCOL_FILES are defined in previous cells\n# Also assuming the load_protocol function is defined\ntry:\n    df_train_full_eval = load_protocol(PROTOCOL_FILES[\"train\"], AUDIO_DIRS[\"train\"])\n    df_dev_full_eval = load_protocol(PROTOCOL_FILES[\"dev\"], AUDIO_DIRS[\"dev\"])\n    df_eval_full_eval = load_protocol(PROTOCOL_FILES[\"eval\"], AUDIO_DIRS[\"eval\"])\n\n    if df_train_full_eval.empty and df_dev_full_eval.empty and df_eval_full_eval.empty:\n        raise ValueError(\"All full dataframes are empty. Check data paths and loading.\")\n\n    print(\"Creating datasets and data loaders for full original data...\")\n    # Assuming AudioDataset, feature_extractor, TARGET_SAMPLE_RATE, MAX_LENGTH,\n    # DataLoader, collate_fn, BATCH_SIZE, and NUM_WORKERS are defined\n    # Use a smaller batch size if memory is an issue with full datasets\n    FULL_DATA_BATCH_SIZE = 32 # Adjust as needed\n\n    if not df_train_full_eval.empty:\n        train_dataset_full = AudioDataset(df_train_full_eval, feature_extractor, TARGET_SAMPLE_RATE, MAX_LENGTH)\n        train_loader_full = DataLoader(train_dataset_full, batch_size=FULL_DATA_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n                                       collate_fn=collate_fn, pin_memory=True, persistent_workers=(NUM_WORKERS > 0))\n        print(f\"Full Train loader batches approx: {len(train_loader_full)}\")\n    else:\n        train_loader_full = None\n        print(\"Full Train dataframe is empty. Skipping full train evaluation.\")\n\n\n    if not df_dev_full_eval.empty:\n        dev_dataset_full = AudioDataset(df_dev_full_eval, feature_extractor, TARGET_SAMPLE_RATE, MAX_LENGTH)\n        dev_loader_full = DataLoader(dev_dataset_full, batch_size=FULL_DATA_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n                                     collate_fn=collate_fn, pin_memory=True, persistent_workers=(NUM_WORKERS > 0))\n        print(f\"Full Dev loader batches approx: {len(dev_loader_full)}\")\n    else:\n        dev_loader_full = None\n        print(\"Full Dev dataframe is empty. Skipping full dev evaluation.\")\n\n    if not df_eval_full_eval.empty:\n        eval_dataset_full = AudioDataset(df_eval_full_eval, feature_extractor, TARGET_SAMPLE_RATE, MAX_LENGTH)\n        eval_loader_full = DataLoader(eval_dataset_full, batch_size=FULL_DATA_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n                                     collate_fn=collate_fn, pin_memory=True, persistent_workers=(NUM_WORKERS > 0))\n        print(f\"Full Eval loader batches approx: {len(eval_loader_full)}\")\n    else:\n        eval_loader_full = None\n        print(\"Full Eval dataframe is empty. Skipping full eval evaluation.\")\n\n\n    # --- Load the Best Model for Evaluation ---\n    # Assuming the best model was saved to BEST_MODEL_NAME in MODEL_SAVE_PATH\n    # Make sure this path is correct and the file exists\n    best_model_filepath = os.path.join(MODEL_SAVE_PATH, BEST_MODEL_NAME)\n\n    if 'model' not in locals() or model is None:\n        print(\"Model object not found. Re-initializing model architecture.\")\n        # Assuming XLSRClassificationModel and MODEL_IDENTIFIER are defined\n        model = XLSRClassificationModel(\n            model_identifier=MODEL_IDENTIFIER,\n        ).to(DEVICE)\n        # Assuming the best model is from the fine-tuning stage where layers were unfrozen\n        # ADJUST num_layers based on your fine-tuning setup\n        model.unfreeze_encoder(num_layers=8) # Adjust num_layers based on your fine-tuning setup\n        model.to(DEVICE)\n\n\n    if os.path.exists(best_model_filepath):\n        try:\n            print(f\"\\nLoading best model state dictionary from {best_model_filepath}\")\n            # Use map_location to ensure it loads correctly onto the current device\n            # Use weights_only=True for safety\n            model.load_state_dict(torch.load(best_model_filepath, map_location=DEVICE, weights_only=True))\n            print(\"Successfully loaded model state dictionary.\")\n\n            # --- Perform Evaluation on Full Data Loaders ---\n            # Assuming criterion and DEVICE are defined in previous cells\n            if 'criterion' in locals() and criterion is not None:\n\n                if train_loader_full is not None:\n                    print(\"\\nEvaluating on Full Training Set:\")\n                    # Assuming evaluate function is defined and returns 5 values including t-DCF\n                    train_loss_full, train_acc_full, train_eer_full, train_auc_full, train_min_tdcf_full = evaluate(\n                        model, train_loader_full, criterion, DEVICE, return_tdcf=True\n                    )\n                    print(f\"Full Train Loss: {train_loss_full:.4f}, Full Train Acc: {train_acc_full:.4f}, Full Train EER: {train_eer_full:.4f}, Full Train AUC: {train_auc_full:.4f}, Full Train min t-DCF: {train_min_tdcf_full:.4f}\")\n\n                if dev_loader_full is not None:\n                    print(\"\\nEvaluating on Full Development Set:\")\n                    dev_loss_full, dev_acc_full, dev_eer_full, dev_auc_full, dev_min_tdcf_full = evaluate(\n                        model, dev_loader_full, criterion, DEVICE, return_tdcf=True\n                    )\n                    print(f\"Full Dev Loss: {dev_loss_full:.4f}, Full Dev Acc: {dev_acc_full:.4f}, Full Dev EER: {dev_eer_full:.4f}, Full Dev AUC: {dev_auc_full:.4f}, Full Dev min t-DCF: {dev_min_tdcf_full:.4f}\")\n\n                if eval_loader_full is not None:\n                    print(\"\\nEvaluating on Full Evaluation Set:\")\n                    eval_loss_full, eval_acc_full, eval_eer_full, eval_auc_full, eval_min_tdcf_full = evaluate(\n                        model, eval_loader_full, criterion, DEVICE, return_tdcf=True\n                    )\n                    print(f\"Full Eval Loss: {eval_loss_full:.4f}, Full Eval Acc: {eval_acc_full:.4f}, Full Eval EER: {eval_eer_full:.4f}, Full Eval AUC: {eval_auc_full:.4f}, Full Eval min t-DCF: {eval_min_tdcf_full:.4f}\")\n\n            else:\n                print(\"Error: Criterion is not defined or is None. Cannot perform evaluation.\")\n\n        except Exception as e:\n            print(f\"Error loading model state dictionary or during evaluation on full data: {e}\")\n    else:\n        print(f\"Error: Best model file not found at {best_model_filepath}. Please ensure training completed successfully and the path is correct.\")\n\nexcept NameError:\n    print(\"Error: Required variables or functions (DATASET_PATH, AUDIO_DIRS, PROTOCOL_FILES, load_protocol, AudioDataset, feature_extractor, TARGET_SAMPLE_RATE, MAX_LENGTH, DataLoader, collate_fn, BATCH_SIZE, NUM_WORKERS, XLSRClassificationModel, MODEL_IDENTIFIER, DEVICE, evaluate, criterion, MODEL_SAVE_PATH, BEST_MODEL_NAME) are not defined. Please run previous cells.\")\nexcept ValueError as ve:\n    print(f\"Error: {ve}\")\nexcept Exception as e:\n    print(f\"An unexpected error occurred during full data evaluation setup: {e}\")\n\n# Clean up full dataframes and loaders to free memory\ndel df_train_full_eval, df_dev_full_eval, df_eval_full_eval\ndel train_dataset_full, dev_dataset_full, eval_dataset_full\ndel train_loader_full, dev_loader_full, eval_loader_full\ngc.collect()\nif DEVICE.type == 'cuda': torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T19:58:53.027977Z","iopub.execute_input":"2025-11-08T19:58:53.028570Z","iopub.status.idle":"2025-11-08T21:03:38.937205Z","shell.execute_reply.started":"2025-11-08T19:58:53.028547Z","shell.execute_reply":"2025-11-08T21:03:38.936104Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating on Full Original Data ---\nLoading full original protocols...\nLoaded ASVspoof2019.LA.cm.train.trn.txt: 25380 samples total (2580 real, 22800 fake)\nLoaded ASVspoof2019.LA.cm.dev.trl.txt: 24844 samples total (2548 real, 22296 fake)\nLoaded ASVspoof2019.LA.cm.eval.trl.txt: 71237 samples total (7355 real, 63882 fake)\nCreating datasets and data loaders for full original data...\nFull Train loader batches approx: 794\nFull Dev loader batches approx: 777\nFull Eval loader batches approx: 2227\n\nLoading best model state dictionary from /kaggle/working/wav2vec2_deepfake_best.pt\nSuccessfully loaded model state dictionary.\n\nEvaluating on Full Training Set:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/794 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-19.39  18.98]\n [-17.86  17.52]\n [-19.39  19.02]\n [-18.44  18.12]\n [-17.72  17.39]]\nProbabilities (first 5): \n[[0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]]\nPositive Class Probs (first 10): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nFull Train Loss: 0.3673, Full Train Acc: 0.9621, Full Train EER: 0.0113, Full Train AUC: 0.9890, Full Train min t-DCF: 0.0227\n\nEvaluating on Full Development Set:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/777 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [1 1 1 1 1 1 1 1 1 1]\nLogits (first 5): \n[[-17.31  17.03]\n [-20.05  19.7 ]\n [-21.33  20.97]\n [-17.89  17.58]\n [-21.25  20.86]]\nProbabilities (first 5): \n[[0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]]\nPositive Class Probs (first 10): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 1 1 1]\n--- End Diagnostics ---\nFull Dev Loss: 0.3419, Full Dev Acc: 0.9668, Full Dev EER: 0.0106, Full Dev AUC: 0.9899, Full Dev min t-DCF: 0.0213\n\nEvaluating on Full Evaluation Set:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/2227 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 0 0 0 0 1 0 1 0 0]\nLogits (first 5): \n[[ 14.016 -13.31 ]\n [  7.168  -6.742]\n [  9.97   -9.47 ]\n [ 17.55  -16.75 ]\n [ 16.86  -16.08 ]]\nProbabilities (first 5): \n[[1.e+00 0.e+00]\n [1.e+00 9.e-07]\n [1.e+00 0.e+00]\n [1.e+00 0.e+00]\n [1.e+00 0.e+00]]\nPositive Class Probs (first 10): [0.e+00 9.e-07 0.e+00 0.e+00 0.e+00 1.e+00 0.e+00 1.e+00 0.e+00 1.e+00]\nPredicted Binary (first 10): [0 0 0 0 0 1 0 1 0 1]\n--- End Diagnostics ---\nFull Eval Loss: 1.3299, Full Eval Acc: 0.8241, Full Eval EER: 0.0649, Full Eval AUC: 0.9355, Full Eval min t-DCF: 0.1298\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# --- 11. Save the Final Model (Best Fine-tuned State) ---\n# The BEST_MODEL_NAME checkpoint already saves the best model based on Val EER during fine-tuning.\n# We can optionally save this best model again with a different name if desired,\n# but saving it as BEST_MODEL_NAME during training is sufficient.\n# This step is mostly for confirming the path or saving a final state if training finished without early stopping.\nfinal_model_filepath = os.path.join(MODEL_SAVE_PATH, FINAL_MODEL_NAME)\n\n# Load the best model state before saving it as \"final\" if training stopped early\n# This ensures FINAL_MODEL_NAME is truly the best state based on validation EER.\nbest_model_filepath_during_ft = os.path.join(MODEL_SAVE_PATH, BEST_MODEL_NAME)\nif os.path.exists(best_model_filepath_during_ft):\n     try:\n         print(f\"\\nLoading best model state from {best_model_filepath_during_ft} to save as final.\")\n         model.load_state_dict(torch.load(best_model_filepath_during_ft, map_location=DEVICE, weights_only=True))\n         torch.save(model.state_dict(), final_model_filepath)\n         print(f\"Final best model state saved at: {final_model_filepath}\")\n     except Exception as e:\n         print(f\"Error loading best model state for final save: {e}. Skipping final save.\")\nelse:\n    print(f\"\\nWarning: Best model checkpoint '{best_model_filepath_during_ft}' not found. Skipping final save.\")\n\n\n# --- Optional: Plot Training History (Requires matplotlib) ---\ntry:\n    import matplotlib.pyplot as plt\n\n    def plot_combined_history(history_initial, history_fine_tune, metric='loss'):\n        \"\"\"Plots a metric from both initial and fine-tuning phases.\"\"\"\n        plt.figure(figsize=(12, 5))\n        total_epochs_initial = len(history_initial.get(metric, []))\n        total_epochs_ft = len(history_fine_tune.get(metric, []))\n        epochs_initial = range(1, total_epochs_initial + 1)\n        if history_initial.get(metric):\n            plt.plot(epochs_initial, history_initial[metric], 'bo-', label=f'Initial Training {metric.capitalize()}')\n        val_metric = f'val_{metric}'\n        if history_initial.get(val_metric):\n            plt.plot(epochs_initial, history_initial[val_metric], 'ro-', label=f'Initial Validation {metric.capitalize()}')\n\n        epochs_ft_total = range(total_epochs_initial + 1, total_epochs_initial + total_epochs_ft + 1)\n        if history_fine_tune.get(metric):\n            plt.plot(epochs_ft_total, history_fine_tune[metric], 'go-', label=f'Fine-tuning {metric.capitalize()}')\n        if history_fine_tune.get(val_metric):\n             plt.plot(epochs_ft_total, history_fine_tune[val_metric], 'mo-', label=f'Fine-tuning Validation {metric.capitalize()}')\n\n        # Add plotting for eval metrics if they exist\n        eval_metric = f'eval_{metric}'\n        if history_initial.get(eval_metric):\n             plt.plot(epochs_initial, history_initial[eval_metric], 'co--', label=f'Initial Evaluation {metric.capitalize()}')\n        if history_fine_tune.get(eval_metric):\n             plt.plot(epochs_ft_total, history_fine_tune[eval_metric], 'yo--', label=f'Fine-tuning Evaluation {metric.capitalize()}')\n\n\n        plt.title(f'Model {metric.capitalize()} During Training')\n        plt.xlabel('Epoch')\n        plt.ylabel(metric.capitalize())\n        handles, labels = plt.gca().get_legend_handles_labels()\n        if handles: plt.legend()\n        plt.grid(True)\n        plt.show()\n\n    print(\"\\nPlotting training history...\")\n    if history and history_ft: # Check if histories exist\n        plot_combined_history(history, history_ft, metric='loss')\n        plot_combined_history(history, history_ft, metric='acc')\n        plot_combined_history(history, history_ft, metric='eer')\n        plot_combined_history(history, history_ft, metric='auc')\n        # Plot t-DCF history from the eval set\n        plot_combined_history(history, history_ft, metric='min_tdcf')\n    else:\n        print(\"Skipping plotting as one or both history objects are missing.\")\n\nexcept ImportError:\n    print(\"\\nMatplotlib not found. Skipping history plotting.\")\nexcept Exception as e:\n    print(f\"\\nError during plotting: {e}\")\n\nprint(\"\\nScript finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T19:53:45.945447Z","iopub.execute_input":"2025-11-08T19:53:45.946026Z","iopub.status.idle":"2025-11-08T19:53:48.677992Z","shell.execute_reply.started":"2025-11-08T19:53:45.946004Z","shell.execute_reply":"2025-11-08T19:53:48.677368Z"},"id":"pYSQ1TMiEMFk","outputId":"75e9d59f-a508-48af-e988-6e51e3d8f060"},"outputs":[{"name":"stdout","text":"\nLoading best model state from /kaggle/working/wav2vec2_deepfake_best.pt to save as final.\nFinal best model state saved at: /kaggle/working/wav2vec2_deepfake_final.pt\n\nPlotting training history...\n\nError during plotting: x and y must have same first dimension, but have shapes (0,) and (15,)\n\nScript finished.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"## PREDICT","metadata":{"id":"kdr_28wAr9JP"}},{"cell_type":"code","source":"# --- 12. Prediction Function ---\ndef predict_single_audio(model, audio_path, feature_extractor, device, target_sr=TARGET_SAMPLE_RATE, max_length=MAX_LENGTH):\n    \"\"\"Predicts the class of a single audio file.\"\"\"\n    model.eval() # Set model to evaluation mode\n    try:\n        waveform, sample_rate = torchaudio.load(audio_path)\n\n        # Preprocessing steps (same as in the Dataset)\n        if waveform.shape[0] > 1:\n            waveform = torch.mean(waveform, dim=0, keepdim=True)\n\n        if sample_rate != target_sr:\n             waveform = torchaudio.functional.resample(waveform, orig_freq=sample_rate, new_freq=target_sr)\n\n        if waveform.shape[1] > max_length:\n            waveform = waveform[:, :max_length]\n\n        # Process using the feature extractor\n        inputs = feature_extractor(\n            waveform.squeeze(0),\n            sampling_rate=target_sr,\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            max_length=max_length,\n            truncation=True\n        )\n\n        input_values = inputs.input_values.to(device) # Move to device\n\n        with torch.no_grad():\n            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n                 logits = model(input_values)\n        probabilities = torch.softmax(logits, dim=1) # Get probabilities\n\n        # Get the predicted class (0 for spoof, 1 for bonafide)\n        predicted_class = torch.argmax(probabilities, dim=1).item()\n\n        # Get the confidence score for the predicted class\n        confidence = probabilities[0, predicted_class].item()\n\n        return predicted_class, confidence, probabilities.squeeze().cpu().numpy() # Return probabilities as numpy array\n\n    except FileNotFoundError:\n        print(f\"Error: Audio file not found at {audio_path}\")\n        return None, None, None\n    except Exception as e:\n        print(f\"Error processing audio file {audio_path}: {e}\")\n        return None, None, None\n\n# --- Example Usage ---\nprint(\"\\n--- Example Prediction ---\")\n\n# Assuming you have an example audio file path.\n# Replace with a real path from your dataset or another file.\n# You might need to find a specific file in your downloaded dataset structure.\n# Example: Get a sample path from the eval dataframe\nif not df_eval.empty:\n    example_audio_path = df_eval.iloc[0]['filepath']\n    print(f\"Using example audio file: {example_audio_path}\")\n\n    # Assuming 'model' is the best fine-tuned model loaded previously\n    # (This should be the case if the previous cells ran successfully)\n    if 'model' in locals() and model is not None:\n        predicted_class, confidence, probabilities = predict_single_audio(model, example_audio_path, feature_extractor, DEVICE)\n\n        if predicted_class is not None:\n            label_map = {0: \"Spoof (Fake)\", 1: \"Bonafide (Real)\"}\n            predicted_label = label_map.get(predicted_class, \"Unknown\")\n\n            print(f\"Predicted Class: {predicted_label}\")\n            print(f\"Confidence: {confidence:.4f}\")\n            print(f\"Probabilities (Spoof, Bonafide): {probabilities}\")\n        else:\n            print(\"Prediction failed.\")\n    else:\n        print(\"Error: Model not found. Please ensure the training/fine-tuning cells ran successfully.\")\nelse:\n    print(\"Error: Evaluation dataframe is empty. Cannot get an example audio file.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T07:11:48.509954Z","iopub.execute_input":"2025-10-31T07:11:48.510641Z","iopub.status.idle":"2025-10-31T07:11:49.357402Z","shell.execute_reply.started":"2025-10-31T07:11:48.510617Z","shell.execute_reply":"2025-10-31T07:11:49.356596Z"},"_kg_hide-output":true,"id":"__nTcA-dr9JQ","outputId":"397f1d7c-51a3-468d-a78b-7e0e05871b90"},"outputs":[{"name":"stdout","text":"\n--- Example Prediction ---\nUsing example audio file: /kaggle/input/asvspoof2019-la/LA/ASVspoof2019_LA_eval/flac/LA_E_9719105.flac\nPredicted Class: Spoof (Fake)\nConfidence: 0.5278\nProbabilities (Spoof, Bonafide): [0.528  0.4724]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# --- 13. Load the Best Model and Predict ---\nprint(\"\\n--- Loading Best Model and Making a Prediction ---\")\n\n# Assuming the best model was saved to BEST_MODEL_NAME in MODEL_SAVE_PATH\nbest_model_filepath = \"/kaggle/input/wav2vec/pytorch/default/1/wav2vec2_deepfake_best.pt\"\n\n# Ensure model object exists and is on the correct device\nif 'model' not in locals() or model is None:\n     print(\"Error: Model object not found. Re-initializing model for loading.\")\n     model = XLSRClassificationModel(\n         model_identifier=MODEL_IDENTIFIER,\n     ).to(DEVICE)\n     # Ensure the encoder is unfrozen if you plan to do further fine-tuning or evaluation on unfrozen layers\n     # If you only need prediction, you can keep it frozen or unfreeze based on how it was trained\n     # For this example, we assume the best model is from the fine-tuning stage where layers were unfrozen\n     model.unfreeze_encoder(num_layers=8) # Adjust num_layers based on your fine-tuning setup\n     model.to(DEVICE)\n\n\nif os.path.exists(best_model_filepath):\n    try:\n        # Load the state dictionary\n        model.load_state_dict(torch.load(best_model_filepath, map_location=DEVICE))\n        print(f\"Successfully loaded model from {best_model_filepath}\")\n\n        # --- User Input for Audio File Path ---\n        # Replace this with the path to the audio file you want to predict\n        audio_file_to_predict = \"/kaggle/input/asvspoof2019-la/LA/ASVspoof2019_LA_eval/flac/LA_E_6262749.flac\" # Example path\n\n        print(f\"Using audio file for prediction: {audio_file_to_predict}\")\n\n        if os.path.exists(audio_file_to_predict):\n            predicted_class, confidence, probabilities = predict_single_audio(model, audio_file_to_predict, feature_extractor, DEVICE)\n\n            if predicted_class is not None:\n                label_map = {0: \"Spoof (Fake)\", 1: \"Bonafide (Real)\"}\n                predicted_label = label_map.get(predicted_class, \"Unknown\")\n\n                print(f\"Predicted Class: {predicted_label}\")\n                print(f\"Confidence: {confidence:.4f}\")\n                print(f\"Probabilities (Spoof, Bonafide): {probabilities}\")\n            else:\n                print(\"Prediction failed for the specified audio file.\")\n        else:\n            print(f\"Error: Audio file not found at {audio_file_to_predict}. Please check the path.\")\n\n\n    except Exception as e:\n        print(f\"Error loading model state dictionary or making prediction: {e}\")\nelse:\n    print(f\"Error: Best model file not found at {best_model_filepath}. Please ensure training completed successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T07:58:55.267417Z","iopub.execute_input":"2025-10-31T07:58:55.268011Z","iopub.status.idle":"2025-10-31T07:58:56.09665Z","shell.execute_reply.started":"2025-10-31T07:58:55.267987Z","shell.execute_reply":"2025-10-31T07:58:56.095841Z"},"id":"UXwVVO0yr9JQ","outputId":"9001474e-29f0-49d5-b1fb-13ef8a6285fa"},"outputs":[{"name":"stdout","text":"\n--- Loading Best Model and Making a Prediction ---\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3743744542.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(best_model_filepath, map_location=DEVICE))\n","output_type":"stream"},{"name":"stdout","text":"Successfully loaded model from /kaggle/input/wav2vec/pytorch/default/1/wav2vec2_deepfake_best.pt\nUsing audio file for prediction: /kaggle/input/test-lll/20251031_hello_my_n.flac\nPredicted Class: Bonafide (Real)\nConfidence: 0.7944\nProbabilities (Spoof, Bonafide): [0.2056 0.7944]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# --- 10. Final Evaluation ---\nprint(\"\\n--- Final Evaluation (Best Fine-tuned Model) ---\")\n\n# --- User Input for Model File Path to Evaluate ---\n# REPLACE THIS with the actual path to the model file you want to evaluate (.pt or .pth)\n# If you want to evaluate the best model saved during the fine-tuning, use BEST_MODEL_NAME.\n# If you want to evaluate the final saved model, use FINAL_MODEL_NAME.\n# If you want to evaluate a different model, provide its full path.\nmodel_file_to_evaluate = \"/kaggle/input/xlsr/pytorch/default/1/xlsr_initial_best.pt\" # Default to best fine-tuned model\n\nprint(f\"Attempting to evaluate model from: {model_file_to_evaluate}\")\n\n# Re-initialize the model architecture to match the saved state_dict\n# This assumes the same model class (XLSRClassificationModel) and parameters (MODEL_IDENTIFIER)\ntry:\n    # Assuming XLSRClassificationModel and MODEL_IDENTIFIER are defined in previous cells\n    model_for_evaluation = XLSRClassificationModel(\n        model_identifier=MODEL_IDENTIFIER,\n    ).to(DEVICE)\n    # Unfreeze layers as needed based on how the saved model was trained\n    # For this example, we assume it was fine-tuned with 8 layers unfrozen\n    model_for_evaluation.unfreeze_encoder(num_layers=8)\n    model_for_evaluation.to(DEVICE)\n    print(\"Model architecture initialized for loading.\")\nexcept NameError:\n    print(\"Error: XLSRClassificationModel or MODEL_IDENTIFIER not defined. Please run previous cells.\")\n    model_for_evaluation = None\nexcept Exception as e:\n    print(f\"Error initializing model architecture for loading: {e}\")\n    model_for_evaluation = None\n\n\nif model_for_evaluation is not None and os.path.exists(model_file_to_evaluate):\n    try:\n        # Load the state dictionary\n        # Use map_location to ensure it loads correctly onto the current device (CPU or GPU)\n        # Use weights_only=True for safety in future PyTorch versions\n        model_for_evaluation.load_state_dict(torch.load(model_file_to_evaluate, map_location=DEVICE, weights_only=True))\n        print(f\"Successfully loaded model state dictionary from {model_file_to_evaluate}\")\n\n        # --- Evaluate the Loaded Model ---\n        print(\"\\n--- Evaluating the Loaded Model ---\")\n        # Assuming dev_loader, eval_loader, criterion, and DEVICE are defined in previous cells\n        if ('dev_loader' in locals() and dev_loader is not None and\n            'eval_loader' in locals() and eval_loader is not None and\n            'criterion' in locals() and criterion is not None):\n\n             print(\"\\nEvaluating on Development Set:\")\n             # Unpack 4 values including AUC\n             dev_loss, dev_acc, dev_eer, dev_auc = evaluate(model_for_evaluation, dev_loader, criterion, DEVICE)\n             print(f\"Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_acc:.4f}, Dev EER: {dev_eer:.4f}, Dev AUC: {dev_auc:.4f}\")\n\n             print(\"\\nEvaluating on Evaluation Set:\")\n             # Unpack 4 values including AUC\n             eval_loss, eval_acc, eval_eer, eval_auc = evaluate(model_for_evaluation, eval_loader, criterion, DEVICE)\n             print(f\"Eval Loss: {eval_loss:.4f}, Eval Acc: {eval_acc:.4f}, Eval EER: {eval_eer:.4f}, Eval AUC: {eval_auc:.4f}\")\n\n             # Optional: Generate Classification Report\n             if 'generate_report' in locals():\n                 generate_report(model_for_evaluation, dev_loader, DEVICE, \"Loaded Model Dev\")\n                 generate_report(model_for_evaluation, eval_loader, DEVICE, \"Loaded Model Eval\")\n             else:\n                  print(\"Warning: generate_report function not found. Skipping classification reports.\")\n\n\n        else:\n            print(\"Error: Data loaders or criterion are not defined or are None. Cannot perform evaluation.\")\n\n\n    except Exception as e:\n        print(f\"Error loading model state dictionary or during evaluation: {e}\")\nelse:\n    if model_for_evaluation is None:\n        print(\"Error: Model architecture could not be initialized. Cannot load state dict.\")\n    elif not os.path.exists(model_file_to_evaluate):\n        print(f\"Error: Model file not found at {model_file_to_evaluate}. Please check the path.\")\n    else:\n        print(\"An unknown error occurred during model loading or evaluation setup.\")\n\n# Remove model_for_evaluation to free up memory if needed\n# del model_for_evaluation\n# if DEVICE.type == 'cuda': torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T02:28:43.509722Z","iopub.execute_input":"2025-10-31T02:28:43.510328Z","iopub.status.idle":"2025-10-31T02:30:03.009587Z","shell.execute_reply.started":"2025-10-31T02:28:43.510304Z","shell.execute_reply":"2025-10-31T02:30:03.008757Z"},"colab":{"referenced_widgets":[""]},"id":"VZwvJcpir9JR","outputId":"b2c668db-2ff8-4841-9c6f-c3e3622dc2ce"},"outputs":[{"name":"stdout","text":"\n--- Final Evaluation (Best Fine-tuned Model) ---\nAttempting to evaluate model from: /kaggle/input/xlsr/pytorch/default/1/xlsr_initial_best.pt\nLoading pre-trained model: facebook/wav2vec2-xls-r-300m\nFreezing encoder layers...\nEncoder layers frozen.\nModel hidden size: 1024\nUnfreezing the top 8 encoder layers...\nModel architecture initialized for loading.\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3875062183.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model_for_evaluation.load_state_dict(torch.load(model_file_to_evaluate, map_location=DEVICE))\n","output_type":"stream"},{"name":"stdout","text":"Successfully loaded model state dictionary from /kaggle/input/xlsr/pytorch/default/1/xlsr_initial_best.pt\n\n--- Evaluating the Loaded Model ---\n\nEvaluating on Development Set:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Batch 0 Diagnostics ---\nLabels (first 10): [0 1 1 0 0 1 0 0 1 0]\nLogits (first 5): \n[[-0.4875  0.933 ]\n [-1.053   1.531 ]\n [-1.298   1.723 ]\n [-0.68    1.116 ]\n [-0.689   1.119 ]]\nProbabilities (first 5): \n[[0.1946 0.8057]\n [0.0702 0.9297]\n [0.0465 0.9536]\n [0.1423 0.858 ]\n [0.1409 0.8594]]\nPositive Class Probs (first 10): [0.8057 0.9297 0.9536 0.858  0.8594 0.9194 0.8857 0.223  0.964  0.809 ]\nPredicted Binary (first 10): [1 1 1 1 1 1 1 0 1 1]\n--- End Diagnostics ---\nError loading model state dictionary or during evaluation: not enough values to unpack (expected 4, got 3)\n","output_type":"stream"}],"execution_count":null}]}